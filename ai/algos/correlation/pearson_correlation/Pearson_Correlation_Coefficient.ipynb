{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson correlation coefficient\n",
    "\n",
    "In [statistics](https://en.wikipedia.org/wiki/Statistics), the __Pearson correlation coefficient__  ― also known as __Pearson's r__, the __Pearson product-moment correlation coefficient (PPMCC)__, the __bivariate correlation__, or colloquially simply as the __correlation coefficient__ ― is the measure of linear correlation between two sets of data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "\n",
    "Pearson's correlation coefficient is the covariance of the two variables divided by the product of their standard deviations. The form of the definition involves a \"product moment\", that is, the mean of the product of the mean-adjusted random variables; hence the modifier product-moment in the name."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For a population\n",
    "\n",
    "Pearson's correlation coefficient, when applied to a [population](https://en.wikipedia.org/wiki/Statistical_population), is commonly represented by the Greek letter ρ (rho) and may be referred to as the _population correlation coefficient_ or the _population Pearson correlation coefficient_. Given a pair of random variables $(X, Y)$, the formula for ρ is:\n",
    "\n",
    "$$ρ_{X,Y}=\\dfrac{cov(X,Y)}{\\sigma_{X}\\sigma_{Y}}$$\n",
    "\n",
    "where:\n",
    "\n",
    "* __cov__ is the [covariance](https://en.wikipedia.org/wiki/Covariance).\n",
    "* $\\sigma_{X}$ is the [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation) of $X$.\n",
    "* $\\sigma_{Y}$ is the [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation) of $Y$.\n",
    "\n",
    "The formula for ρ can be expressed in terms of mean and expectation. Since\n",
    "\n",
    "$$cov(X,Y)=\\mathbb{E}[(X-μ_{X})(Y-μ_{Y})],$$\n",
    "\n",
    "the formula for ρ can also be written as\n",
    "\n",
    "$$ρ_{X,Y}=\\dfrac{\\mathbb{E}[(X-μ_{X})(Y-μ_{Y})]}{\\sigma_{X}\\sigma_{Y}}$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $\\sigma_{X}$ and $\\sigma_{Y}$ are defined as above.\n",
    "* $μ_{X}$ is the [mean](https://en.wikipedia.org/wiki/Mean) of $X$.\n",
    "* $μ_{Y}$ is the [mean](https://en.wikipedia.org/wiki/Mean) of $Y$.\n",
    "* $\\mathbb{E}$ is the [expectation](https://en.wikipedia.org/wiki/Expected_Value).\n",
    "\n",
    "The formula for ρ can be expressed in terms of uncentered moments. Since\n",
    "\n",
    "* $μ_{X} = \\mathbb{E}[X]$\n",
    "* $μ_{Y} = \\mathbb{E}[Y]$\n",
    "* $\\sigma^{2}_{X} = \\mathbb{E}[(X-\\mathbb{E}[X])^{2}] = \\mathbb{E}[X^{2}] - (\\mathbb{E}[X])^{2}$\n",
    "* $\\sigma^{2}_{Y} = \\mathbb{E}[(Y-\\mathbb{E}[Y])^{2}] = \\mathbb{E}[Y^{2}] - (\\mathbb{E}[Y])^{2}$\n",
    "* $\\mathbb{E}[(X-μ_{X})(Y-μ_{Y})] = \\mathbb{E}[(X-\\mathbb{E}[X])(Y-\\mathbb{E}[Y])] = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]$\n",
    "\n",
    "the formula for ρ can also be written as\n",
    "\n",
    "$$ρ_{X,Y} = \\dfrac{\\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]}{\\sqrt{\\mathbb{E}[X^{2}] - (\\mathbb{E}[X])^{2}}\\sqrt{\\mathbb{E}[Y^{2}] - (\\mathbb{E}[Y])^{2}}}$$\n",
    "\n",
    "Pearson's correlation coefficient does not exist when either $\\sigma_{X}$ or $\\sigma_{Y}$ are zero, infinite, or undefined."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\"\"\"An implementation of Pearson's correlation coefficient algorithm.\"\"\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cov(m: np.array,\n",
    "        y: np.array = None,\n",
    "        rowvar: bool = True,\n",
    "        bias: bool = False,\n",
    "        ddof: int = None,\n",
    "        fweights: np.array = None,\n",
    "        aweights: np.array = None,\n",
    "        *,\n",
    "        dtype: np.dtype = None) -> np.ndarray:\n",
    "  \"\"\"Estimate a covariance matrix, given data and weights.\n",
    "\n",
    "  Covariance indicates the level to which two variables vary together.\n",
    "  If we examine N-dimensional samples, :math:`X = [x_1, x_2, ... x_N]^T`, then\n",
    "  the covariance matrix element :math:`C_{ij}` is the covariance of :math:`x_i`\n",
    "  and :math:`x_j`. The element :math:`C_{ii}` is the variance of :math:`x_i`.\n",
    "\n",
    "  Args:\n",
    "    m:        A 1-D or 2-D array containing multiple variables and observations.\n",
    "              Each row of `m` represents a variable, and each column a single\n",
    "              observation of all those variables. Also see `rowvar` below.\n",
    "    y:        An additional set of variables and observations. `y` has the same\n",
    "              form as that of `m`.\n",
    "    rowvar:   If `rowvar` is True (default), then each row represents a\n",
    "              variable, with observations in the columns. Otherwise,\n",
    "              relationship is transposed: each column represents a variable,\n",
    "              while the rows contains observations.\n",
    "    bias:     Default normalization (False) is by ``(N - 1)``, where ``N`` is\n",
    "              the number of observations given (unbiased estimate). If `bias` is\n",
    "              True, then normalization is by ``N``. These values can be\n",
    "              overriden by using the keyword ``ddof``.\n",
    "    ddof:     If not ``None`` then the default value implied by `bias` is\n",
    "              overridden. Note that ``ddof=1`` will return the unbiased\n",
    "              estimate, even if both `fweights` and `aweights` are specified,\n",
    "              and ``ddof=0`` will return the simple average.\n",
    "    fweights: 1-D array of integer frequency weight; the number of times each\n",
    "              observation vector should be repeated.\n",
    "    aweights: 1-D array of observation vector weights. These relative weights\n",
    "              are typically large for observations considered \"important\" and\n",
    "              smaller for observations considered less \"important\". If\n",
    "              ``ddof=0`` the array of weights can be used to assign\n",
    "              probabilities to observation vectors.\n",
    "    dtype:    Data type of the result. By default the return data type will\n",
    "              have at least `numpy.float64` precision.\n",
    "\n",
    "    Returns:\n",
    "      The covariance matrix of the variables.\n",
    "\n",
    "    Notes:\n",
    "      Assume that the observations are in the columns of the observation array\n",
    "      `m` and let ``f=fweights`` and ``a=aweights`` for brevity. The steps to\n",
    "      compute the weighted covariance are as follows:\n",
    "\n",
    "          >>> m = np.arange(10, dtype=np.float64)\n",
    "          >>> f = np.arange(10) * 2\n",
    "          >>> a = np.arange(10) ** 2\n",
    "          >>> ddof = 1\n",
    "          >>> w = f * a\n",
    "          >>> v1 = np.sum(w)\n",
    "          >>> v2 = np.sum(w * a)\n",
    "          >>> m -= np.sum(m * w, axis=None, keepdims=True) / v1\n",
    "          >>> cov = np.dot(m * w, m.T) * v1 / ((v1 ** 2) - (ddof * v2))\n",
    "\n",
    "      Note that when ``a == 1``, the normalization factor\n",
    "      ``v1 / (v1**2 - ddof * v2)`` goes over to ``1 / (np.sum(f) - ddof)`` as it\n",
    "      should.\n",
    "  \"\"\"\n",
    "  if ddof is not None and ddof != int(ddof):\n",
    "    raise ValueError('ddof must be integer')\n",
    "\n",
    "  # Handling complex arrays too.\n",
    "  m = np.asarray(m)\n",
    "  if m.ndim > 2:\n",
    "    raise ValueError('m has more than 2 dimensions')\n",
    "\n",
    "  if y is not None:\n",
    "    y = np.asarray(y)\n",
    "    if y.ndim > 2:\n",
    "      raise ValueError('y has more than 2 dimensions')\n",
    "\n",
    "  if dtype is None:\n",
    "    if y is None:\n",
    "      dtype = np.result_type(m, np.float64)\n",
    "    else:\n",
    "      dtype = np.result_type(m, y, np.float64)\n",
    "\n",
    "  x = np.array(m, ndmin=2, dtype=dtype)\n",
    "  if not rowvar and x.shape[0] != 1:\n",
    "    x = x.T\n",
    "  if x.shape[0] == 0:\n",
    "    return np.array([]).reshape(0, 0)\n",
    "  if y is not None:\n",
    "    y = np.array(y, copy=False, ndmin=2, dtype=dtype)\n",
    "    if not rowvar and y.shape[0] != 1:\n",
    "      y = y.T\n",
    "    x = np.concatenate((x, y), axis=0)\n",
    "\n",
    "  if ddof is None:\n",
    "    if bias == 0:\n",
    "      ddof = 1\n",
    "    else:\n",
    "      ddof = 0\n",
    "\n",
    "  # Get the product of frequencies and weights.\n",
    "  w = None\n",
    "  if fweights is not None:\n",
    "    fweights = np.asarray(fweights, dtype=float)\n",
    "    if not np.all(fweights == np.around(fweights)):\n",
    "      raise TypeError('fweights must be integer')\n",
    "    if fweights.ndim > 1:\n",
    "      raise RuntimeError('Cannot handle multidimensional fweights')\n",
    "    if fweights.shape[0] != x.shape[1]:\n",
    "      raise RuntimeError('Incompatible number of samples and fweights')\n",
    "    if any(fweights < 0):\n",
    "      raise ValueError('fweights cannot be negative')\n",
    "    w = fweights\n",
    "\n",
    "  if aweights is not None:\n",
    "    aweights = np.asarray(aweights, dtype=float)\n",
    "    if aweights.ndim > 1:\n",
    "      raise RuntimeError('Cannot handle multidimensional aweights')\n",
    "    if aweights.shape[0] != x.shape[1]:\n",
    "      raise RuntimeError('Incompatible number of samples and fweights')\n",
    "    if any(aweights < 0):\n",
    "      raise ValueError('aweights cannot be negative')\n",
    "    if w is None:\n",
    "      w = aweights\n",
    "    else:\n",
    "      w *= aweights\n",
    "\n",
    "  avg, w_sum = np.average(x, axis=1, weights=w, returned=True)\n",
    "  w_sum = w_sum[0]\n",
    "\n",
    "  # Determine the normalization.\n",
    "  if w is None:\n",
    "    fact = x.shape[1] - ddof\n",
    "  elif ddof == 0:\n",
    "    fact = w_sum\n",
    "  elif aweights is None:\n",
    "    fact = w_sum - ddof\n",
    "  else:\n",
    "    fact = w_sum - ddof * sum(w * aweights) / w_sum\n",
    "\n",
    "  if fact <= 0:\n",
    "    warnings.warn('Degrees of freedom <= 0 for slice',\n",
    "                  RuntimeWarning,\n",
    "                  stacklevel=3)\n",
    "    fact = 0.0\n",
    "\n",
    "  x -= avg[:, None]\n",
    "  x_T = None  # pylint: disable=invalid-name\n",
    "  if w is None:\n",
    "    x_T = x.T  # pylint: disable=invalid-name\n",
    "  else:\n",
    "    x_T = (x * w).T  # pylint: disable=invalid-name\n",
    "  c = np.dot(x, x_T.conj())\n",
    "  c *= np.true_divide(1, fact)\n",
    "  return c.squeeze()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6f2081d9e0b7d32ecec298930d2c84146e44d12c2a59792b9d51f0a2535e83c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
