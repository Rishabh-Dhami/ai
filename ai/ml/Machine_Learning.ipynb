{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TwWj-1U8BrAv"
      },
      "source": [
        "# Introduction to ML\n",
        "\n",
        "Machine learning is a field of inquiry devoted to understanding and building methods that __'learn'__, that is, methods that leverage data to improve performance on some set of tasks. It is seen as a part of artificial intelligence.\n",
        "\n",
        "## Additional information\n",
        "\n",
        "* _Rules of Machine Learning,_ [Rule #1: Don't be afraid to launch a product without machine learning](https://developers.google.com/machine-learning/rules-of-ml/#rule_1_dont_be_afraid_to_launch_a_product_without_machine_learning)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Framing\n",
        "\n",
        "What is (supervised) machine learning? Concisely put, it is the following:\n",
        "\n",
        "* ML systems learn how to combine input to produce useful predictions on never-before-seen data.\n",
        "\n",
        "Let's explore fundamental machine learning terminology.\n",
        "\n",
        "## Labels\n",
        "\n",
        "A __label__ is the thing we are predicting - the `y` variable in simple linear regression. The label could be the future price of wheat, the kind of animal shown in the picture, the meaning of an audio clip, or just about anything.\n",
        "\n",
        "## Features\n",
        "\n",
        "A __feature__ is an input variable - the `x` variable in simple linera regression. A simple machine learning project might use a single feature, while a more sophisticated machine learning project could use millions of features, specified as:\n",
        "\n",
        "$$x1,x2,...,xn$$\n",
        "\n",
        "In the \"spam detector\" example, the features could include the following:\n",
        "\n",
        "* words in the email text\n",
        "* sender's address\n",
        "* time of day the email was sent\n",
        "* email contains the phrase \"one weird trick.\"\n",
        "\n",
        "## Examples\n",
        "\n",
        "An __example__ is a particular instance of data, __x__. (We put __x__ in boldface to indicate that it is a vector.) We break __examples__ into two categories:\n",
        "\n",
        "* labeled examples\n",
        "* unlabeled examples\n",
        "\n",
        "A __labeled example__ includes both feature(s) and the label. That is:\n",
        "\n",
        "```\n",
        "labeled examples: {features, label}: (x, y)\n",
        "```\n",
        "\n",
        "Use __labeled examples__ to train the model. In our \"span detector\" example, the labeled examples would be individual emails that users have explicitly marked as \"spam\" or \"not spam.\"\n",
        "\n",
        "For example, the following table shows 5 labeled examples from a data set containing information about housing prices in California:\n",
        "\n",
        "__HousingMedianAge (feature)__ | __TotalRooms (feature)__ | __TotalBedrooms (feature)__ | __MedianHouseValue (feature)__\n",
        ":--|:--:|:--:|--:\n",
        "15 | 5612 | 1283 | 66900\n",
        "19 | 7650 | 1901 | 80100\n",
        "17 | 720 | 174 | 85700\n",
        "14 |\t1501 |\t337\t| 73400\n",
        "20\t| 1454 |\t326 |\t65500\n",
        "\n",
        "An __unlabeled example__ contains feature(s) but not the label. That is:\n",
        "\n",
        "```\n",
        "unlabeled examples: {features, ?}: (x, ?)\n",
        "```\n",
        "\n",
        "Here are 3 unlabeled examples from the same housing dataset, which exclude __`MedianHouseValue`__:\n",
        "\n",
        "__HousingMedianAge (feature)__ |\t__TotalRooms (feature)__ |\t__TotalBedrooms (feature)__\n",
        ":--|:--:|--:\n",
        "42 |\t1686 |\t361\n",
        "34 |\t1226 |\t180\n",
        "33 |\t1077 |\t271\n",
        "\n",
        "Once we've trained our model with labeled examples, we use that model to predict the label on unlabeled examples. In the spam detector, unlabeled examples are new emails that humans haven't yet labeled.\n",
        "\n",
        "## Models\n",
        "\n",
        "A model defines the relationship between feature(s) and label. For example, a span detector might associate certain features strongly with \"spam\". Let's highlight two phases of a model's life:\n",
        "\n",
        "* __Training__ means __creating__ or __learning__ the model. That is, you show the model labeled examples and enable the model to gradually learn the relationships between features and label.\n",
        "\n",
        "* __Inference__ means applying the trained model to unlabeled examples. That is, you use the trained model to make useful predictions (`y'`). For example, during __inference__, you can predict __MedianHouseValue__ for new unlabeled examples.\n",
        "\n",
        "## Regression vs. classification\n",
        "\n",
        "A __regression__ model predicts continuous values. For example, regression models make predictions that answer questions like the following:\n",
        "\n",
        "* What is the value of a house in California?\n",
        "* What is the probability that a user will click on this ad?\n",
        "\n",
        "A __classification__ model predicts discrete values. For example, classification models make predictions that answer questions like the following:\n",
        "\n",
        "* Is a given email message spam or not spam?\n",
        "* Is this an image of a dog, a cat, or a hamster?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check your understanding\n",
        "\n",
        "__Supervised Learning__\n",
        "\n",
        "__Q1. Suppose you want to develop a supervised machine learning model to predict whether a given email is \"spam\" or \"not spam.\" What are the true statements that you can think about for being a useful label?__\n",
        "\n",
        "> * __Emails not marked as \"spam\" or \"not spam\" are unlabeled examples.__ <br>\n",
        ">    Because our label consists of the values \"spam\" and \"not spam\", any email not yet marked as spam or not spam is an unlabeled example.\n",
        ">\n",
        "> * __The labels applied to some examples might be unreliable.__ <br>\n",
        ">    Definitely. It's important to check how reliable your data is. The labels for this dataset probably come from email users who mark particular email messages as spam. Since most users do not mark every suspicious email message as spam, we may have trouble knowing whether an email is spam. Furthermore, spammers could intentionally poison our model by providing faulty labels.\n",
        "\n",
        "__Features and Labels__\n",
        "\n",
        "__Q1. Suppose an online shoe store wants to create a supervised ML model that will provide personalized shoe recommendations to users. That is, the model will recommend certain pairs of shoes to Marty and different pairs of shoes to Janet. The system will use past user behavior data to generate training data. What are the true statements that you can think of for being a useful label?__\n",
        "\n",
        "> * __\"Shoe size\" is a useful feature.__ <br>\n",
        "> \"Shoe size\" is a quantifiable signal that likely has a strong impact on whether the user will like the recommended shoes. For example, if Marty wears size 9, the model shouldn't recommend size 7 shoes.\n",
        ">\n",
        "> * __\"The user clicked on the shoe's description\" is a useful label.__ <br>\n",
        "> Users probably only want to read more about those shoes that they like. Clicks by users is, therefore, an observable, quantifiable metric that could serve as a good training label. Since our training data derives from past user behavior, our labels need to derive from objective behaviors like clicks that strongly correlate with user preferences.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Descending into ML\n",
        "\n",
        "Linear regression is a method for finding the straight line or hyperplane that best fits a set of points."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Regression\n",
        "\n",
        "It has long been known that crickets (an insect species) chirp more frequently on hotter days than on cooler days. For decades, professional and amateur scientists have cataloged data on chirps-per-minute and temperature. As a birthday gift, your Aunt Ruth gives you her cricket database and asks you to learn a model to predict this relationship. Using this data, you want to explore this relationship.\n",
        "\n",
        "First, examine your data by plotting it:\n",
        "\n",
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/CricketPoints.svg' />\n",
        "\n",
        "  <strong>Figure 1. Chirps per Minute vs. Temperature in Celsius.</strong>\n",
        "</div>\n",
        "\n",
        "As expected, the plot shows the temperature rising with the number of chirps. Is this relationship between chirps and temperature linear? Yes, you could draw a single straight line like the following to approximate this relationship:\n",
        "\n",
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/CricketLine.svg' />\n",
        "\n",
        "  <strong>Figure 2. A linear relationship.</strong>\n",
        "</div>\n",
        "\n",
        "True, the line doesn't pass through every dot, but the line does clearly show the relationship between chirps and temperature. Using the equation for a line, you could write down this relationship as follows:\n",
        "\n",
        "$$y=mx+b$$\n",
        "\n",
        "where:\n",
        "\n",
        "*  $y$ is the temperature in Celsius — the value we're trying to predict.\n",
        "* $m$ is the slope of the line.\n",
        "* $x$ is the number of chirps per minute — the value of our input feature.\n",
        "* $b$ is the y-intercept.\n",
        "\n",
        "By convention in machine learning, you'll write the equation for a model slightly differently:\n",
        "\n",
        "$$y^\\prime=b+w_{1}x_{1}$$\n",
        "\n",
        "where:\n",
        "\n",
        "* $y^\\prime$ is a predicted [label](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology#labels) (a desired output).\n",
        "* $b$ is the bias (the y-intercept), sometimes referred to as $w_{0}$.\n",
        "* $w_{1}$ is the [weight](https://developers.google.com/machine-learning/glossary#weight) of feature 1. Weight is the same concept as the \"slope\" _$m$_ in the traditional equation of a line.\n",
        "* $x_{1}$ is a [feature](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology#features) (a known input).\n",
        "\n",
        "To __infer__ (predict) the temprature $y^\\prime$ for new chirps-per-minute value $x_{1}$, just substitute the $x_{1}$ value into this model.\n",
        "\n",
        "Although this model uses only one feature, a more sophisticated model might rely on multiple features, each having a separate weight ($w_{1}$, $w_{2}$, etc.). For example, a model that relies on three features might look as follows:\n",
        "\n",
        "$$y^\\prime=b+w_{1}x_{1}+w_{2}x_{2}+w_{3}x_{3}$$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Loss\n",
        "\n",
        "__Training__ a model simply means learning (determining) good values for all the weights and the bias from labeled examples. In supervised learning, a machine learning algorithm builds a model by examining many examples and attempting to find a model that minimizes loss; this process is called __empirical risk minimization__.\n",
        "\n",
        "Loss is the penalty for a bad prediction. That is, __loss__ is a number indicating how bad the model's prediction was on a single example. If the model's prediction is perfect, the loss is zero; otherwise, the loss is greater. The goal of training a model is to find a set of weights and biases that have low loss, on average, across all examples. For example, Figure 3 shows a high loss model on the left and a low loss model on the right. Note the following about the figure:\n",
        "\n",
        "* The arrows represent loss.\n",
        "* The blue lines represent predictions.\n",
        "\n",
        "<div algin='center'>\n",
        "  <img src='https://developers.google.com/machine-learning/crash-course/images/LossSideBySide.png' />\n",
        "\n",
        "  <strong>Figure 3. High loss in the left model; low loss in the right model.</strong>\n",
        "</div>\n",
        "\n",
        "Notice that the arrows in the left plot are much longer than their counterparts in the right plot. Clearly, the line in the right plot is a much better predictive model than the line in the left plot.\n",
        "\n",
        "You might be wondering whether you could create a mathematical function — a loss function — that would aggregate the individual losses in a meaningful fashion."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Squared loss: a popular loss function\n",
        "\n",
        "The linear regression models we'll examine here use a loss function called __squared loss__ (also known as __L2 loss__). The __squared loss__ for a single example is as follows:\n",
        "\n",
        "```\n",
        "  = the square of the difference between the label and the prediction\n",
        "  = (observation - prediction(x))2\n",
        "  = (y - y')2\n",
        "```\n",
        "\n",
        "__Mean square error (MSE)__ is the average squared loss per example over the whole dataset. To calculate __MSE__, sum up all the squared losses for individual examples and then divide by the number of examples:\n",
        "\n",
        "$$\\mathrm{MSE}=\\dfrac{1}{N}\\sum_{(x,y) \\in D} (y - \\mathrm{prediction}(x))^2$$\n",
        "\n",
        "where:\n",
        "\n",
        "* $(x,y)$ is an example in which\n",
        "  * $x$ is a set of features (for example chirps/minute, age, gender) that the model uses to make predictions.\n",
        "  * $y$ is the example's label (for example, temprature).\n",
        "* $prediction(x)$ is a function of the weights and bias in combination with the sets of features $x$.\n",
        "* $D$ is a dataset containing many labeled examples, which are $(x,y)$ pairs.\n",
        "* $N$ is the number of examples in $D$.\n",
        "\n",
        "Although MSE is commonly-used in machine learning, it is neither the only practical loss function nor the best loss function for all circumstances."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check your understanding\n",
        "\n",
        "__Mean Squared Error__\n",
        "\n",
        "Consider the following two plots:\n",
        "\n",
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/MCEDescendingIntoMLLeft.png' />\n",
        "\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/MCEDescendingIntoMLRight.png' />\n",
        "</div>\n",
        "\n",
        "__Q1. Which of the two data sets shown in the preceding plots has the higher Mean Squared Error (MSE)?__\n",
        "\n",
        "> __The dataset on the right.__ <br>\n",
        "> The eight examples on the line incur a total loss of 0. However, although only two points lay off the line, both of those points are twice as far off the line as the outlier points in the left figure. Squared loss amplifies those differences, so an offset of two incurs a loss four times as great as an offset of one.\n",
        "> $$\\mathrm{MSE}=\\dfrac{0^2+0^2+0^2+2^2+0^2+0^2+0^2+2^2+0^2+0^2}{10}=0.8$$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reducing Loss\n",
        "\n",
        "To train a model, we need a good way to reduce the model’s loss. An iterative approach is one widely used method for reducing loss, and is as easy and efficient as walking down a hill."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## An iterative approach\n",
        "\n",
        "Iterative learning might remind you of the \"[Hot and Cold](http://www.howcast.com/videos/258352-how-to-play-hot-and-cold/)\" kid's game for finding a hidden object like a thimble. In this game, the \"hidden object\" is the best possible model. You'll start with a wild guess (\"The value of $w_{1}$ is $0$.\") and wait for the system to tell you what the loss is. Then, you'll try another guess (\"The value of $w_{1}$ is $0.5$.\") and see what the loss is. Aah, you're getting warmer. Actually, if you play this game right, you'll usually be getting warmer. The real trick to the game is trying to find the best possible model as efficiently as possible.\n",
        "\n",
        "The following figure suggests the iterative trial-and-error process that machine learning algorithms use to train a model:\n",
        "\n",
        "<div align='center'>\n",
        "  <img src=\"https://developers.google.com/static/machine-learning/crash-course/images/GradientDescentDiagram.svg\" />\n",
        "\n",
        "  <strong>Figure 1. An iterative approach to training a model.</strong>\n",
        "</div>\n",
        "\n",
        "Iterative strategies are prevalent in machine learning, primarily because they scale so well to large data sets.\n",
        "\n",
        "The \"model\" takes one or more features as input and returns one prediction ($y′$) as output. To simplify, consider a model that takes one feature and returns one prediction:\n",
        "\n",
        "$$y′=b+w_{1}x_{1}$$\n",
        "\n",
        "What initial values should we set for $b$ and $w_{1}$? For linear regression problems, it turns out that the starting values aren't important. We could pick random values, but we'll just take the following trivial values instead:\n",
        "\n",
        "* $b=0$\n",
        "* $w_{1}=0$\n",
        "\n",
        "Suppose that the first feature value is 10. Plugging that feature value into the prediction function yields:\n",
        "\n",
        "$$y′=0+0⋅10=0$$\n",
        "\n",
        "The \"Compute Loss\" part of the diagram is the [loss function](https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss) that the model will use. Suppose we use the squared loss function. The loss function takes in two input values:\n",
        "\n",
        "* $y′$: The model's prediction for features $x$\n",
        "* $y$: The correct label corresponding to features $x$\n",
        "\n",
        "At last, we've reached the \"Compute parameter updates\" part of the diagram. It is here that the machine learning system examines the value of the loss function and generates new values for $b$ and $w_{1}$. For now, just assume that this mysterious box devises new values and then the machine learning system re-evaluates all those features against all those labels, yielding a new value for the loss function, which yields new parameter values. And the learning continues iterating until the algorithm discovers the model parameters with the lowest possible loss. Usually, you iterate until overall loss stops changing or at least changes extremely slowly. When that happens, we say that the model has [__converged__](https://developers.google.com/machine-learning/glossary#convergence)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradient Descent\n",
        "\n",
        "The iterative approach diagram contained a green hand-wavy box entitled \"Compute parameter updates.\" We'll now replace that algorithmic fairy dust with something more substantial."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose we had the time and the computing resources to calculate the loss for all possible values of $w_{1}$. For the kind of regression problems we've been examining, the resulting plot of loss vs. $w_{1}$ will always be convex. In other words, the plot will always be bowl-shaped, kind of like this:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src=\"https://developers.google.com/static/machine-learning/crash-course/images/convex.svg\" />\n",
        "\n",
        "  <strong>Figure 2. Regression problems yield convex loss vs. weight plots.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convex problems have only one minimum; that is, only one place where the slope is exactly 0. That minimum is where the loss function converges.\n",
        "\n",
        "Calculating the loss function for every conceivable value of $w_{1}$ over the entire data set would be an inefficient way of finding the convergence point. Let's examine a better mechanism—very popular in machine learning—called __gradient descent__.\n",
        "\n",
        "The first stage in gradient descent is to pick a starting value (a starting point) for $w_{1}$. The starting point doesn't matter much; therefore, many algorithms simply set $w_{1}$ to $0$ or pick a random value. The following figure shows that we've picked a starting point slightly greater than $0$:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/GradientDescentStartingPoint.svg' />\n",
        "  \n",
        "  <strong>Figure 3. A starting point for gradient descent.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The gradient descent algorithm then calculates the gradient of the loss curve at the starting point. Here in this Figure, the gradient of the loss is equal to the [derivative](https://wikipedia.org/wiki/Differential_calculus#The_derivative) (slope) of the curve, and tells you which way is \"warmer\" or \"colder.\" When there are multiple weights, the gradient is a vector of partial derivatives with respect to the weights."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Partial derivatives\n",
        "\n",
        "A __multivariable function__ is a function with more than one argument, such as:\n",
        "\n",
        "$$f(x,y)=e^{2y}\\mathrm{sin}(x)$$\n",
        "\n",
        "The __partial derivate__ $f$ __with respect to__ $x$, denoted as follows:\n",
        "\n",
        "$$\\dfrac{∂f}{∂x}$$\n",
        "\n",
        "is a derivative of $f$ considered as a function of $x$ alone. To find the following:\n",
        "\n",
        "$$\\dfrac{∂f}{∂x}$$\n",
        "\n",
        "so must hold $y$ constant (so $f$ is now a function of one variable $x$), and take the regular derivative of $f$ with respect to $x$. For example, when $y$ is fixed at $1$, the preceding function becomes:\n",
        "\n",
        "$$f(x)=e^{2}\\mathrm{sin}(x)$$\n",
        "\n",
        "This is just a function of one variable $x$, whose derivative is:\n",
        "\n",
        "$$e^{2}\\mathrm{cos}(x)$$\n",
        "\n",
        "In general, thinking of $y$ as fixed, the partial derivative of $f$ with respect to $x$ is calculated as follows:\n",
        "\n",
        "$$\\dfrac{∂f}{∂x}(x,y)=e^{2y}\\mathrm{sin}(x)$$\n",
        "\n",
        "Similarly, if we hold $x$ fixed instead, the partial derivative of $f$ with respect to $y$ is:\n",
        "\n",
        "$$\\dfrac{∂f}{∂x}(x,y)=2e^{2y}\\mathrm{sin}(x)$$\n",
        "\n",
        "Intuitively, a partial derivative tells how much the function changes when you perturb one variable a bit. In the preceding example:\n",
        "\n",
        "$$\\dfrac{\\partial f}{\\partial x}(0,1)=e^2 \\approx 7.4$$\n",
        "\n",
        "So when you start at $(0,1)$, hold $y$ constant, and move $x$ a little, $f$ changes by about $7.4$ times the amount that you changed $x$.\n",
        "\n",
        "In machine learning, partial derivatives are mostly used in conjunction with the gradient of a function."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gradients\n",
        "\n",
        "The __gradient__ of a function, denoted as follows, is the vector of partial derivatives with respect to all of the independent variables:\n",
        "\n",
        "$$∇f$$\n",
        "\n",
        "For instance, if:\n",
        "\n",
        "$$f(x,y)=e^{2y}\\mathrm{sin}(x)$$\n",
        "\n",
        "then:\n",
        "\n",
        "$$∇f(x,y)= \\left( \\dfrac{\\partial f}{\\partial x}(x,y), \\dfrac{\\partial f}{\\partial y}(x,y) \\right)=(e^{2y}\\mathrm{cos}(x), 2e^{2y}\\mathrm{sin}(x))$$\n",
        "\n",
        "Note the following:\n",
        "\n",
        "* $∇f$ - Points in the direction of greatest increase of the function.\n",
        "* $−∇f$ - Points in the direction of greatest decrease of the function.\n",
        "\n",
        "The number of dimensions in a vector is equal to the number of variables in the formula for $f$; in other words, the vector falls within the domain space of the function. For instance, the graph of the following function $f(x,y)$:\n",
        "\n",
        "$$f(x,y)=4+(x−2)^2+2y^2$$\n",
        "\n",
        "when viewed in three dimensions with $z=f(x,y)$ looks like a valley with a minimum at $(2,0,4)$:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/ThreeDimensionalPlot.svg' />\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The gradient of $f(x,y)$ is a two-dimensional vector that tells you in which $(x,y)$ direction to move for the maximum increase in height. Thus, the negative of the gradient moves you in the direction of maximum decrease in height. In other words, the negative of the gradient vector points into the valley.\n",
        "\n",
        "In machine learning, gradients are used in gradient descent. We often have a loss function of many variables that we are trying to minimize, and we try to do this by following the negative of the gradient of the function."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Okay, so comming back to our gradient descent. We've found that a gradient is a vector that has both of the following characterstics:\n",
        "\n",
        "* A direction\n",
        "* A magnitude\n",
        "\n",
        "The gradient always points in the direction of steepest increase in the loss function. The gradient descent algorithm takes a step in the direction of the negative gradient in order to reduce loss as quickly as possible."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/GradientDescentNegativeGradient.svg' />\n",
        "\n",
        "  <strong>Figure 4. Gradient descent relies on negative gradients.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To determine the next point along the loss function curve, the gradient descent algorithm adds some fraction of the gradient's magnitude to the starting point as shown in the following figure:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/GradientDescentGradientStep.svg' />\n",
        "\n",
        "  <strong>Figure 5. A gradient step moves us to the next point on the loss curve.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The gradient descent then repeats this process, edging ever closer to the minimum."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Rate\n",
        "\n",
        "As noted, the gradient vector has both a direction and a magnitude. Gradient descent algorithms multiply the gradient by a scalar known as the __learning rate__ (also sometimes called __step size__) to determine the next point. For example, if the gradient magnitude is $2.5$ and the learning rate is $0.01$, then the gradient descent algorithm will pick the next point $0.025$ away from the previous point.\n",
        "\n",
        "__Hyperparameters__ are the knobs that programmers tweak in machine learning algorithms. Most machine learning programmers spend a fair amount of time tuning the learning rate. If you pick a learning rate that is too small, learning will take too long:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/LearningRateTooSmall.svg' />\n",
        "\n",
        "  <strong>Figure 6. Learning rate is too small.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conversely, if you specify a learning rate that is too large, the next point will perpetually bounce haphazardly across the bottom of the well like a quantum mechanics experiment gone horribly wrong:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/LearningRateTooLarge.svg' />\n",
        "\n",
        "  <strong>Figure 7. Learning rate is too large.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There's a [Goldilocks](https://wikipedia.org/wiki/Goldilocks_principle) learning rate for every regression problem. The Goldilocks value is related to how flat the loss function is. If you know the gradient of the loss function is small then you can safely try a larger learning rate, which compensates for the small gradient and results in a larger step size."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/LearningRateJustRight.svg' />\n",
        "\n",
        "  <strong>Figure 8. Learning rate is just right.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ideal learning rate in one-dimension is $\\dfrac{1}{f(x)″}$ (the inverse of the second derivative of $f(x)$ at $x$).\n",
        "\n",
        "The ideal learning rate for $2$ or more dimensions is the inverse of the [Hessian](https://wikipedia.org/wiki/Hessian_matrix) (matrix of second partial derivatives).\n",
        "\n",
        "The story for general convex functions is more complex."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stochastic Gradient Descent\n",
        "\n",
        "__Stochastic Gradient Descent (SGD)__ is an optimization algorithm used to find the minimum of a function. It is a type of gradient descent algorithm that is often used in machine learning and deep learning. It is called \"stochastic\" because it uses random samples of the data to estimate the gradient of the objective function, rather than using the entire dataset.\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "* The algorithm starts with an initial guess of the parameters.\n",
        "* It then selects a random sample of the data and calculates the gradient of the objective function with respect to the parameters using that sample.\n",
        "* The parameters are then updated in the direction opposite to the gradient.\n",
        "* This process is repeated until the parameters converge to a minimum of the objective function.\n",
        "\n",
        "One of the main advantage of stochastic gradient descent is that it is computationally efficient. Because it uses a random sample of the data at each step, it can be much faster than batch gradient descent, which uses the entire dataset to calculate the gradient. Additionally, because it uses random samples, it can \"escape\" from local minima and converge to a global minimum.\n",
        "\n",
        "An example of an application of __SGD__ is Linear Regression, where the objective function is the mean squared error and the parameters are the weights of the model. Another example is Logistic Regression, where the objective function is the cross-entropy loss and the parameters are the weights of the model.\n",
        "\n",
        "It should be noted that the optimization speed of __SGD__ can be affected by the choice of the learning rate and the shuffling of the data during each iteration. Also it is not guaranteed to find the global minimum because of the randomness but it can be useful in practice.\n",
        "\n",
        "In summary, __Stochastic Gradient Descent__ is an optimization algorithm that is efficient and can help to find the global minimum of a function. It has been widely used in machine learning and deep learning tasks."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### __Check Your Understanding__\n",
        "\n",
        "__Q1. When performing gradient descent on a large data set, which of the following batch sizes will likely be more efficient?__\n",
        "\n",
        "> __A small batch or even a batch of one example (SGD).__\n",
        ">\n",
        "> Amazingly enough, performing gradient descent on a small batch or even a batch of one example is usually more efficient than the full batch. After all, finding the gradient of one example is far cheaper than finding the gradient of millions of examples. To ensure a good representative sample, the algorithm scoops up another random small batch (or batch of one) on every iteration."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to TensorFlow\n",
        "\n",
        "TensorFlow is an end-to-end open source platform for machine learning. TensorFlow is a rich system for managing all aspects of a machine learning system; however, this class focuses on using a particular TensorFlow API to develop and train machine learning models. See the [TensorFlow documentation](https://tensorflow.org/) for complete details on the broader TensorFlow system.\n",
        "\n",
        "TensorFlow APIs are arranged hierarchically, with the high-level APIs built on the low-level APIs. Machine learning researchers use the low-level APIs to create and explore new machine learning algorithms. In this class, you will use a high-level API named tf.keras to define and train machine learning models and to make predictions. tf.keras is the TensorFlow variant of the open-source [Keras](https://keras.io/) API.\n",
        "\n",
        "The following figure shows the hierarchy of TensorFlow toolkits:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/TFHierarchyNew.png' />\n",
        "\n",
        "  <strong>Figure 1. TensorFlow toolkit hierarchy.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear regression with tf.keras"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple Linear regression with Synthetic Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define functions that build and train a model\n",
        "\n",
        "The following code defines two functions:\n",
        "\n",
        "  * `build_model(my_learning_rate)`, which builds an empty model.\n",
        "  * `train_model(model, feature, label, epochs)`, which trains the model from the examples (feature and label) you pass. \n",
        "\n",
        "Since you don't need to understand model building code right now, you may optionally explore this code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential. \n",
        "  # A sequential model contains one or more layers.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Describe the topography of the model.\n",
        "  # The topography of a simple linear regression model\n",
        "  # is a single node in a single layer. \n",
        "  model.add(tf.keras.layers.Dense(units=1, \n",
        "                                  input_shape=(1,)))\n",
        "\n",
        "  # Compile the model topography into code that \n",
        "  # TensorFlow can efficiently execute. Configure \n",
        "  # training to minimize the model's mean squared error. \n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(\n",
        "                                    learning_rate=learning_rate),\n",
        "                loss='mean_squared_error',\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model           \n",
        "\n",
        "\n",
        "def train_model(model, feature, label, epochs, batch_size):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Feed the feature values and the label values to the \n",
        "  # model. The model will train for the specified number \n",
        "  # of epochs, gradually learning how the feature values\n",
        "  # relate to the label values. \n",
        "  history = model.fit(x=feature,\n",
        "                      y=label,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs)\n",
        "\n",
        "  # Gather the trained model's weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the \n",
        "  # rest of history.\n",
        "  epochs = history.epoch\n",
        "  \n",
        "  # Gather the history (a snapshot) of each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  # Specifically gather the model's root mean \n",
        "  # squared error at each epoch. \n",
        "  rmse = hist['root_mean_squared_error']\n",
        "\n",
        "  return trained_weight, trained_bias, epochs, rmse"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define plotting functions\n",
        "\n",
        "We're using a popular Python library called [Matplotlib](https://developers.google.com/machine-learning/glossary/#matplotlib) to create the following two plots:\n",
        "\n",
        "*  a plot of the feature values vs. the label values, and a line showing the output of the trained model.\n",
        "*  a [loss curve](https://developers.google.com/machine-learning/glossary/#loss_curve)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
        "  \"\"\"Plot the trained model against the training feature and label.\"\"\"\n",
        "\n",
        "  # Label the axes.\n",
        "  plt.xlabel('feature')\n",
        "  plt.ylabel('label')\n",
        "\n",
        "  # Plot the feature values vs. label values.\n",
        "  plt.scatter(feature, label)\n",
        "\n",
        "  # Create a red line representing the model. The red line starts\n",
        "  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n",
        "  x0 = 0\n",
        "  y0 = trained_bias\n",
        "  x1 = feature[-1]\n",
        "  y1 = trained_bias + (trained_weight * x1)\n",
        "  plt.plot([x0, x1], [y0, y1], c='r')\n",
        "\n",
        "  # Render the scatter plot and the red line.\n",
        "  plt.show()\n",
        "\n",
        "def plot_the_loss_curve(epochs, rmse):\n",
        "  \"\"\"Plot the loss curve, which shows loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Root Mean Squared Error')\n",
        "\n",
        "  plt.plot(epochs, rmse, label='Loss')\n",
        "  plt.legend()\n",
        "  plt.ylim([rmse.min() * 0.97, rmse.max()])\n",
        "  plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the dataset\n",
        "\n",
        "The dataset consists of 12 [examples](https://developers.google.com/machine-learning/glossary/#example). Each example consists of one [feature](https://developers.google.com/machine-learning/glossary/#feature) and one [label](https://developers.google.com/machine-learning/glossary/#label)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature = ([1.0, 2.0,  3.0,  4.0,  5.0,  6.0,  7.0,  8.0,  9.0, 10.0, 11.0, 12.0])\n",
        "label   = ([5.0, 8.8,  9.6, 14.2, 18.8, 19.5, 21.4, 26.8, 28.9, 32.0, 33.8, 38.2])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specify the hyperparameters\n",
        "\n",
        "The hyperparameters in this Colab are as follows:\n",
        "\n",
        "  * [learning rate](https://developers.google.com/machine-learning/glossary/#learning_rate)\n",
        "  * [epochs](https://developers.google.com/machine-learning/glossary/#epoch)\n",
        "  * [batch_size](https://developers.google.com/machine-learning/glossary/#batch_size)\n",
        "\n",
        "The following code cell initializes these hyperparameters and then invokes the functions that build and train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate=0.01\n",
        "epochs=10\n",
        "batch_size=12\n",
        "\n",
        "model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(model, feature, \n",
        "                                                         label, epochs,\n",
        "                                                         batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, feature, label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1: Examine the graphs\n",
        "\n",
        "Examine the top graph. The blue dots identify the actual data; the red line identifies the output of the trained model. Ideally, the red line should align nicely with the blue dots.  Does it?  Probably not.\n",
        "\n",
        "A certain amount of randomness plays into training a model, so you'll get somewhat different results every time you train.  That said, unless you are an extremely lucky person, the red line probably *doesn't* align nicely with the blue dots.  \n",
        "\n",
        "Examine the bottom graph, which shows the loss curve. Notice that the loss curve decreases but doesn't flatten out, which is a sign that the model hasn't trained sufficiently."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Increase the number of epochs\n",
        "\n",
        "Training loss should steadily decrease, steeply at first, and then more slowly. Eventually, training loss should eventually stay steady (zero slope or nearly zero slope), which indicates that training has [converged](http://developers.google.com/machine-learning/glossary/#convergence).\n",
        "\n",
        "In Task 1, the training loss did not converge. One possible solution is to train for more epochs.  Your task is to increase the number of epochs sufficiently to get the model to converge. However, it is inefficient to train past convergence, so don't just set the number of epochs to an arbitrarily high value.\n",
        "\n",
        "Examine the loss curve. Does the model converge?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate=0.01\n",
        "epochs=450\n",
        "batch_size=12 \n",
        "\n",
        "model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(model, feature, \n",
        "                                                         label, epochs,\n",
        "                                                         batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, feature, label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Increase the learning rate\n",
        "\n",
        "In Task 2, you increased the number of epochs to get the model to converge. Sometimes, you can get the model to converge more quickly by increasing the learning rate. However, setting the learning rate too high often makes it impossible for a model to converge. In Task 3, we've intentionally set the learning rate too high. Run the following code cell and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate=100 \n",
        "epochs=500\n",
        "batch_size = batch_size \n",
        "\n",
        "model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(model, feature, \n",
        "                                                         label, epochs,\n",
        "                                                         batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, feature, label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The resulting model is terrible; the red line doesn't align with the blue dots. Furthermore, the loss curve oscillates like a [roller coaster](https://www.wikipedia.org/wiki/Roller_coaster).  An oscillating loss curve strongly suggests that the learning rate is too high. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4: Find the ideal combination of epochs and learning rate\n",
        "\n",
        "Assign values to the following two hyperparameters to make training converge as efficiently as possible: \n",
        "\n",
        "*  `learning_rate`\n",
        "*  `epochs`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate=0.14\n",
        "epochs=70\n",
        "batch_size = batch_size\n",
        "\n",
        "model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(model, feature, \n",
        "                                                         label, epochs,\n",
        "                                                         batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, feature, label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 5: Adjust the batch size\n",
        "\n",
        "The system recalculates the model's loss value and adjusts the model's weights and bias after each **iteration**.  Each iteration is the span in which the system processes one batch. For example, if the **batch size** is 6, then the system recalculates the model's loss value and adjusts the model's weights and bias after processing every 6 examples.  \n",
        "\n",
        "One **epoch** spans sufficient iterations to process every example in the dataset. For example, if the batch size is 12, then each epoch lasts one iteration. However, if the batch size is 6, then each epoch consumes two iterations.  \n",
        "\n",
        "It is tempting to simply set the batch size to the number of examples in the dataset (12, in this case). However, the model might actually train faster on smaller batches. Conversely, very small batches might not contain enough information to help the model converge. \n",
        "\n",
        "Experiment with `batch_size` in the following code cell. What's the smallest integer you can set for `batch_size` and still have the model converge in a hundred epochs?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate=0.05\n",
        "epochs=125\n",
        "batch_size=1 # Wow, a batch size of 1 works!\n",
        "\n",
        "model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(model, feature, \n",
        "                                                         label, epochs,\n",
        "                                                         batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, feature, label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of hyperparameter tuning\n",
        "\n",
        "Most machine learning problems require a lot of hyperparameter tuning.  Unfortunately, we can't provide concrete tuning rules for every model. Lowering the learning rate can help one model converge efficiently but make another model converge much too slowly.  You must experiment to find the best set of hyperparameters for your dataset. That said, here are a few rules of thumb:\n",
        "\n",
        " * Training loss should steadily decrease, steeply at first, and then more slowly until the slope of the curve reaches or approaches zero. \n",
        " * If the training loss does not converge, train for more epochs.\n",
        " * If the training loss decreases too slowly, increase the learning rate. Note that setting the learning rate too high may also prevent training loss from converging.\n",
        " * If the training loss varies wildly (that is, the training loss jumps around), decrease the learning rate.\n",
        " * Lowering the learning rate while increasing the number of epochs or the batch size is often a good combination.\n",
        " * Setting the batch size to a *very* small batch number can also cause instability. First, try large batch size values. Then, decrease the batch size until you see degradation.\n",
        " * For real-world datasets consisting of a very large number of examples, the entire dataset might not fit into memory. In such cases, you'll need to reduce the batch size to enable a batch to fit into memory. \n",
        "\n",
        "Remember: the ideal combination of hyperparameters is data dependent, so you must always experiment and verify."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Linear Regression with a Real Dataset\n",
        "\n",
        "Now we are going to use a real dataset to predict the prices of houses in California."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Dataset\n",
        "  \n",
        "The [dataset for this exercise](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) is based on 1990 census data from California. The dataset is old but still provides a great opportunity to learn about machine learning programming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The dataset\n",
        "\n",
        "Datasets are often stored on disk or at a URL in [.csv format](https://wikipedia.org/wiki/Comma-separated_values). \n",
        "\n",
        "A well-formed .csv file contains column names in the first row, followed by many rows of data.  A comma divides each value in each row. For example, here are the first five rows of the .csv file holding the California Housing Dataset:\n",
        "\n",
        "```\n",
        "\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"\n",
        "-114.310000,34.190000,15.000000,5612.000000,1283.000000,1015.000000,472.000000,1.493600,66900.000000\n",
        "-114.470000,34.400000,19.000000,7650.000000,1901.000000,1129.000000,463.000000,1.820000,80100.000000\n",
        "-114.560000,33.690000,17.000000,720.000000,174.000000,333.000000,117.000000,1.650900,85700.000000\n",
        "-114.570000,33.640000,14.000000,1501.000000,337.000000,515.000000,226.000000,3.191700,73400.000000\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the .csv file into a pandas DataFrame\n",
        "\n",
        "Like many machine learning programs, we gather the `.csv` file and stores the data in memory as a pandas Dataframe. Pandas is an open source Python library. The primary datatype in pandas is a DataFrame.  You can imagine a pandas DataFrame as a spreadsheet in which each row is identified by a number and each column by a name. Pandas is itself built on another open source Python library called NumPy.\n",
        "\n",
        "The following code cell imports the .csv file into a pandas DataFrame and scales the values in the label (`median_house_value`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the dataset.\n",
        "training_df = pd.read_csv(filepath_or_buffer=\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "\n",
        "# Scale the label.\n",
        "training_df[\"median_house_value\"] /= 1000.0\n",
        "\n",
        "# Print the first rows of the pandas DataFrame.\n",
        "training_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scaling `median_house_value` puts the value of each house in units of thousands. Scaling will keep loss values and learning rates in a friendlier range.  \n",
        "\n",
        "Although scaling a label is usually *not* essential, scaling features in a multi-feature model usually *is* essential."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Examine the dataset\n",
        "\n",
        "A large part of most machine learning projects is getting to know your data. The pandas API provides a `describe` function that outputs the following statistics about every column in the DataFrame:\n",
        "\n",
        "* `count`, which is the number of rows in that column. Ideally, `count` contains the same value for every column. \n",
        "\n",
        "* `mean` and `std`, which contain the mean and standard deviation of the values in each column. \n",
        "\n",
        "* `min` and `max`, which contain the lowest and highest values in each column.\n",
        "\n",
        "* `25%`, `50%`, `75%`, which contain various [quantiles](https://developers.google.com/machine-learning/glossary/#quantile)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get statistics on the dataset.\n",
        "training_df.describe()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 1: Identify anomalies in the dataset\n",
        "\n",
        "Do you see any anomalies (strange values) in the data?\n",
        "\n",
        "> The maximum value (max) of several columns seems very high compared to the other quantiles. For example, example the total_rooms column. Given the quantile values (25%, 50%, and 75%), you might expect the max value of total_rooms to be approximately 5,000 or possibly 10,000. However, the max value is actually 37,937.\n",
        ">\n",
        "> When you see anomalies in a column, become more careful about using that column as a feature. That said, anomalies in potential features sometimes mirror anomalies in the label, which could make the column be (or seem to be) a powerful feature."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define functions that build and train a model\n",
        "\n",
        "The following code defines two functions:\n",
        "\n",
        "  * `build_model(my_learning_rate)`, which builds a randomly-initialized model.\n",
        "  * `train_model(model, feature, label, epochs)`, which trains the model from the examples (feature and label) you pass. \n",
        "\n",
        "Since you don't need to understand model building code right now, you may optionally explore this code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Describe the topography of the model.\n",
        "  # The topography of a simple linear regression model\n",
        "  # is a single node in a single layer.\n",
        "  model.add(tf.keras.layers.Dense(units=1, \n",
        "                                  input_shape=(1,)))\n",
        "\n",
        "  # Compile the model topography into code that TensorFlow can efficiently\n",
        "  # execute. Configure training to minimize the model's mean squared error. \n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(\n",
        "                              learning_rate=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model        \n",
        "\n",
        "\n",
        "def train_model(model, df, feature, label, epochs, batch_size):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Feed the model the feature and the label.\n",
        "  # The model will train for the specified number of epochs. \n",
        "  history = model.fit(x=df[feature],\n",
        "                      y=df[label],\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs)\n",
        "\n",
        "  # Gather the trained model's weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the rest of history.\n",
        "  epochs = history.epoch\n",
        "  \n",
        "  # Isolate the error for each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  # To track the progression of training, we're going to take a snapshot\n",
        "  # of the model's root mean squared error at each epoch. \n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return trained_weight, trained_bias, epochs, rmse"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define plotting functions\n",
        "\n",
        "We're using a popular Python library called [Matplotlib](https://developers.google.com/machine-learning/glossary/#matplotlib) to create the following two plots:\n",
        "\n",
        "*  a plot of the feature values vs. the label values, and a line showing the output of the trained model.\n",
        "*  a [loss curve](https://developers.google.com/machine-learning/glossary/#loss_curve)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
        "  \"\"\"Plot the trained model against 200 random training examples.\"\"\"\n",
        "\n",
        "  # Label the axes.\n",
        "  plt.xlabel(feature)\n",
        "  plt.ylabel(label)\n",
        "\n",
        "  # Create a scatter plot from 200 random points of the dataset.\n",
        "  random_examples = training_df.sample(n=200)\n",
        "  plt.scatter(random_examples[feature], random_examples[label])\n",
        "\n",
        "  # Create a red line representing the model. The red line starts\n",
        "  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n",
        "  x0 = 0\n",
        "  y0 = trained_bias\n",
        "  x1 = random_examples[feature].max()\n",
        "  y1 = trained_bias + (trained_weight * x1)\n",
        "  plt.plot([x0, x1], [y0, y1], c='r')\n",
        "\n",
        "  # Render the scatter plot and the red line.\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_the_loss_curve(epochs, rmse):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, rmse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([rmse.min() * 0.97, rmse.max()])\n",
        "  plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Call the model functions\n",
        "\n",
        "An important part of machine learning is determining which [features](https://developers.google.com/machine-learning/glossary/#feature) correlate with the [label](https://developers.google.com/machine-learning/glossary/#label). For example, real-life home-value prediction models typically rely on hundreds of features and synthetic features. However, this model relies on only one feature. For now, you'll arbitrarily use `total_rooms` as that feature. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 30\n",
        "batch_size = 30\n",
        "\n",
        "# Specify the feature and the label.\n",
        "feature = \"total_rooms\"  # the total number of rooms on a specific city block.\n",
        "label=\"median_house_value\" # the median value of a house on a specific city block.\n",
        "# That is, you're going to create a model that predicts house value based \n",
        "# solely on total_rooms.  \n",
        "\n",
        "# Discard any pre-existing version of the model.\n",
        "model = None\n",
        "\n",
        "# Invoke the functions.\n",
        "model = build_model(learning_rate)\n",
        "weight, bias, epochs, rmse = train_model(model, training_df, \n",
        "                                         feature, label,\n",
        "                                         epochs, batch_size)\n",
        "\n",
        "print(\"\\nThe learned weight for your model is %.4f\" % weight)\n",
        "print(\"The learned bias for your model is %.4f\\n\" % bias )\n",
        "\n",
        "plot_the_model(weight, bias, feature, label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A certain amount of randomness plays into training a model. Consequently, you'll get different results each time you train the model. That said, given the dataset and the hyperparameters, the trained model will generally do a poor job describing the feature's relation to the label."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use the model to make predictions\n",
        "\n",
        "You can use the trained model to make predictions. In practice, [you should make predictions on examples that are not used in training](https://developers.google.com/machine-learning/crash-course/training-and-test-sets/splitting-data). However, for this exercise, you'll just work with a subset of the same training dataset.\n",
        "\n",
        "First, run the following code to define the house prediction function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_house_values(n, feature, label):\n",
        "  \"\"\"Predict house values based on a feature.\"\"\"\n",
        "\n",
        "  batch = training_df[feature][10000:10000 + n]\n",
        "  predicted_values = model.predict_on_batch(x=batch)\n",
        "\n",
        "  print(\"feature   label          predicted\")\n",
        "  print(\"  value   value          value\")\n",
        "  print(\"          in thousand$   in thousand$\")\n",
        "  print(\"--------------------------------------\")\n",
        "  for i in range(n):\n",
        "    print (\"%5.0f %6.0f %15.0f\" % (training_df[feature][10000 + i],\n",
        "                                   training_df[label][10000 + i],\n",
        "                                   predicted_values[i][0] ))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, invoke the house prediction function on 10 examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predict_house_values(10, feature, label)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2: Judge the predictive power of the model\n",
        "\n",
        "Look at the preceding table. How close is the predicted value to the label value?  In other words, does your model accurately predict house values?\n",
        "\n",
        "> Most of the predicted values differ significantly from the label value, so the trained model probably doesn't have much predictive power. However, the first 10 examples might not be representative of the rest of the examples.  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Try a different feature\n",
        "\n",
        "The `total_rooms` feature had only a little predictive power. Would a different feature have greater predictive power?  Try using `population` as the feature instead of `total_rooms`. \n",
        "\n",
        "Note: When you change features, you might also need to change the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pick a feature other than \"total_rooms\"\n",
        "feature = \"population\"\n",
        "\n",
        "# Possibly, experiment with the hyperparameters.\n",
        "learning_rate = 0.05\n",
        "epochs = 18\n",
        "batch_size = 3\n",
        "\n",
        "# Don't change anything below.\n",
        "model = build_model(learning_rate)\n",
        "weight, bias, epochs, rmse = train_model(model, training_df, \n",
        "                                         feature, label,\n",
        "                                         epochs, batch_size)\n",
        "\n",
        "plot_the_model(weight, bias, feature, label)\n",
        "plot_the_loss_curve(epochs, rmse)\n",
        "\n",
        "predict_house_values(10, feature, label)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Did `population` produce better predictions than `total_rooms`?\n",
        "\n",
        "> Training is not entirely deterministic, but population typically converges at a slightly higher RMSE than total_rooms. So, population appears to be about the same or slightly worse at making predictions than total_rooms."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4: Define a synthetic feature\n",
        "\n",
        "You have determined that `total_rooms` and `population` were not useful features.  That is, neither the total number of rooms in a neighborhood nor the neighborhood's population successfully predicted the median house price of that neighborhood. Perhaps though, the *ratio* of `total_rooms` to `population` might have some predictive power. That is, perhaps block density relates to median house value.\n",
        "\n",
        "To explore this hypothesis, do the following: \n",
        "\n",
        "1. Create a [synthetic feature](https://developers.google.com/machine-learning/glossary/#synthetic_feature) that's a ratio of `total_rooms` to `population`.\n",
        "2. Tune the three hyperparameters.\n",
        "3. Determine whether this synthetic feature produces \n",
        "   a lower loss value than any of the single features you \n",
        "   tried earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a synthetic feature\n",
        "training_df[\"rooms_per_person\"] = training_df[\"total_rooms\"] / training_df[\"population\"]\n",
        "feature = \"rooms_per_person\"\n",
        "\n",
        "# Tune the hyperparameters.\n",
        "learning_rate = 0.06\n",
        "epochs = 24\n",
        "batch_size = 30\n",
        "\n",
        "# Don't change anything below this line.\n",
        "model = build_model(learning_rate)\n",
        "weight, bias, epochs, mae = train_model(model, training_df,\n",
        "                                        feature, label,\n",
        "                                        epochs, batch_size)\n",
        "\n",
        "plot_the_model(weight, bias, feature, label)\n",
        "plot_the_loss_curve(epochs, mae)\n",
        "predict_house_values(15, feature, label)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the loss values, this synthetic feature produces a better model than the individual features you tried in Task 2 and Task 3. However, the model still isn't creating great predictions."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 5. Find feature(s) whose raw values correlate with the label\n",
        "\n",
        "So far, we've relied on trial-and-error to identify possible features for the model.  Let's rely on statistics instead.\n",
        "\n",
        "A **correlation matrix** indicates how each attribute's raw values relate to the other attributes' raw values. Correlation values have the following meanings:\n",
        "\n",
        "  * `1.0`: perfect positive correlation; that is, when one attribute rises, the other attribute rises.\n",
        "  * `-1.0`: perfect negative correlation; that is, when one attribute rises, the other attribute falls. \n",
        "  * `0.0`: no correlation; the two columns [are not linearly related](https://en.wikipedia.org/wiki/Correlation_and_dependence#/media/File:Correlation_examples2.svg).\n",
        "\n",
        "In general, the higher the absolute value of a correlation value, the greater its predictive power. For example, a correlation value of -0.8 implies far more predictive power than a correlation of -0.2.\n",
        "\n",
        "The following code cell generates the correlation matrix for attributes of the California Housing Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate a correlation matrix.\n",
        "training_df.corr()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The correlation matrix shows nine potential features (including a synthetic\n",
        "feature) and one label (`median_house_value`).  A strong negative correlation or strong positive correlation with the label suggests a potentially good feature.  \n",
        "\n",
        "**Your Task:** Determine which of the nine potential features appears to be the best candidate for a feature?\n",
        "\n",
        "> The median_income correlates 0.7 with the label (median_house_value), so median_income might be a good feature. The other seven potential features all have a correlation relatively close to 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature = \"median_income\"\n",
        "\n",
        "# Possibly, experiment with the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 10\n",
        "batch_size = 3\n",
        "\n",
        "# Don't change anything below.\n",
        "model = build_model(learning_rate)\n",
        "weight, bias, epochs, rmse = train_model(model, training_df, \n",
        "                                         feature, label,\n",
        "                                         epochs, batch_size)\n",
        "\n",
        "plot_the_model(weight, bias, feature, label)\n",
        "plot_the_loss_curve(epochs, rmse)\n",
        "\n",
        "predict_house_values(10, feature, label)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generalization\n",
        "\n",
        "__Generalization__ refers to your model's ability to adapt properly to new, previously unseen data, drawn from the same distribution as the one used to create the model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Peril of Overfitting\n",
        "\n",
        "This module focuses on generalization. In order to develop some intuition about this concept, you're going to look at three figures. Assume that each dot in these figures represents a tree's position in a forest. The two colors have the following meanings:\n",
        "\n",
        "* The blue dots represent sick trees.\n",
        "* The orange dots represent healthy trees.\n",
        "\n",
        "With that in mind, take a look at Figure 1."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/machine-learning/crash-course/images/GeneralizationA.png' />\n",
        "\n",
        "  <strong>Figure 1. Sick (blue) and healthy (orange) trees.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can you imagine a good model for predicting subsequent sick or healthy trees? Take a moment to mentally draw an arc that divides the blues from the oranges, or mentally [lasso](https://en.wikipedia.org/wiki/Lasso_(statistics)) a batch of oranges or blues. Then, look at Figure 2, which shows how a certain machine learning model separated the sick trees from the healthy trees. Note that this model produced a very low loss."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/machine-learning/crash-course/images/GeneralizationB.png' />\n",
        "\n",
        "  <strong>Figure 2. A complex model for distinguishing sick from healthy trees.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> At first glance, the model shown in Figure 2 appeared to do an excellent job of separating the healthy trees from the sick ones. Or did it?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Low loss, but still a bad model?\n",
        "\n",
        "Figure 3 shows what happened when we added new data to the model. It turned out that the model adapted very poorly to the new data. Notice that the model miscategorized much of the new data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/machine-learning/crash-course/images/GeneralizationC.png' />\n",
        "\n",
        "  <strong>Figure 3. The model did a bad job predicting new data.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model shown in Figures 2 and 3 overfits the peculiarities of the data it trained on. An overfit model gets a low loss during training but does a poor job predicting new data. If a model fits the current sample well, how can we trust that it will make good predictions on new data? As you'll see [later on](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization), overfitting is caused by making a model more complex than necessary. The fundamental tension of machine learning is between fitting our data well, but also fitting the data as simply as possible.\n",
        "\n",
        "Machine learning's goal is to predict well on new data drawn from a (hidden) true probability distribution. Unfortunately, the model can't see the whole truth; the model can only sample from a training data set. If a model fits the current examples well, how can you trust the model will also make good predictions on never-before-seen examples?\n",
        "\n",
        "William of Ockham, a 14th century friar and philosopher, loved simplicity. He believed that scientists should prefer simpler formulas or theories over more complex ones. To put Ockham's razor in machine learning terms:\n",
        "\n",
        "> The less complex an ML model, the more likely that a good empirical result is not just due to the peculiarities of the sample.\n",
        "\n",
        "In modern times, we've formalized Ockham's razor into the fields of __statistical learning theory__ and __computational learning theory__. These fields have developed __generalization bounds__ ̶ a statistical description of a model's ability to generalize to new data based on factors such as:\n",
        "\n",
        "* the complexity of the model\n",
        "* the model's performance on training data\n",
        "\n",
        "A machine learning model aims to make good predictions on new, previously unseen data. But if you are building a model from your data set, how would you get the previously unseen data? Well, one way is to divide your data set into two subsets:\n",
        "\n",
        "* __training set__ — a subset to train a model.\n",
        "* __test set__ — a subset to test the model.\n",
        "\n",
        "Good performance on the test set is a useful indicator of good performance on the new data in general, assuming that:\n",
        "\n",
        "* The test set is large enough.\n",
        "* You don't cheat by using the same test set over and over."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The ML fine print\n",
        "\n",
        "The following three basic assumptions guide generalization:\n",
        "\n",
        "* We draw examples __independently and identically (i.i.d)__ at random from the distribution. In other words, examples don't influence each other. (An alternate explanation: __i.i.d__. is a way of referring to the randomness of variables.)\n",
        "* The distribution is __stationary__; that is the distribution doesn't change within the data set.\n",
        "* We draw examples from partitions from the __same distribution__.\n",
        "\n",
        "In practice, we sometimes violate these assumptions. For example:\n",
        "\n",
        "* Consider a model that chooses ads to display. The i.i.d. assumption would be violated if the model bases its choice of ads, in part, on what ads the user has previously seen.\n",
        "* Consider a data set that contains retail sales information for a year. User's purchases change seasonally, which would violate stationarity.\n",
        "\n",
        "When we know that any of the preceding three basic assumptions are violated, we must pay careful attention to metrics."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training and Test Sets\n",
        "\n",
        "A __test set__ is a data set used to evaluate the model developed from a training set."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting Data\n",
        "\n",
        "* __training set__ - a subset to train a model.\n",
        "* __test set__ - a subset to test the trained model.\n",
        "\n",
        "You could imagine slicing the single data set as follows:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/PartitionTwoSets.svg' />\n",
        "\n",
        "  <strong>Figure 1. Slicing a single data set into a training set and test set.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make sure that your test set meets the following two conditions:\n",
        "\n",
        "* Is large enough to yield statistically meaningful results.\n",
        "* Is representative of the data set as a whole. In other words, don't pick a test set with different characterstics than the training set.\n",
        "\n",
        "Assuming that your test set meets the preceding two conditions, your goal is to create a model that generalizes well to new data. Our test set serves as a proxy for new data. For example, consider the following figure. Notice that the model learned for the training data is very simple. This model doesn't do a perfect job—a few predictions are wrong. However, this model does about as well on the test data as it does on the training data. In other words, this simple model does not overfit the training data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/TrainingDataVsTestData.svg' />\n",
        "\n",
        "  <strong>Figure 2. Validating the trained model against test data.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Never train on test data.__ If you are seeing surprisingly good results on your evaluation metrics, it might be a sign that you are accidentally training on the test set. For example, high accuracy might indicate that test data has leaked into the training set.\n",
        "\n",
        "For example, consider a model that predicts whether an email is spam, using the subject line, email body, and sender's email address as features. We apportion the data into training and test sets, with an 80-20 split. After training, the model achieves 99% precision on both the training set and the test set. We'd expect a lower precision on the test set, so we take another look at the data and discover that many of the examples in the test set are duplicates of examples in the training set (we neglected to scrub duplicate entries for the same spam email from our input database before splitting the data). We've inadvertently trained on some of our test data, and as a result, we're no longer accurately measuring how well our model generalizes to new data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Validation Set\n",
        "\n",
        "Partitioning a data set into a training set and test set lets you judge whether a given model will generalize well to new data. However, using only two partitions may be insufficient when doing many rounds of hyperparameter tuning."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Another Partition\n",
        "\n",
        "Previously, we worked on two partitions of our data set and with those two partitions, the workflow could look as follows:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/WorkflowWithTestSet.svg' />\n",
        "\n",
        "  <strong>Figure 1. A possible workflow?</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the figure, \"Tweak model\" means adjusting anything about the model you can dream up—from changing the learning rate, to adding or removing features, to designing a completely new model from scratch. At the end of this workflow, you pick the model that does best on the _test set_.\n",
        "\n",
        "Dividing the data set into two sets is a good idea, but not a panacea. You can greatly reduce your chances of overfitting by partitioning the data set into the three subsets shown in the following figure:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/PartitionThreeSets.svg' />\n",
        "\n",
        "  <strong>Figure 2. Slicing a single data set into three subsets.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the __validation set__ to evaluate results from the training set. Then, use the test set to double-check your evaluation after the model has \"passed\" the validation set. The following figure shows this new workflow:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/WorkflowWithValidationSet.svg' />\n",
        "\n",
        "  <strong>Figure 3. A better workflow.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this improved workflow:\n",
        "\n",
        "1. Pick the model that does best on the validation set.\n",
        "2. Double-check that model against the test set.\n",
        "\n",
        "This is a better workflow because it creates fewer exposures to the test set."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Representation\n",
        "\n",
        "A machine learning model can't directly see, hear, or sense input examples. Instead, you must create a representation of the data to provide the model with a useful vantage point into the data's key qualities. That is, in order to train a model, you must choose the set of features that best represent the data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n",
        "\n",
        "In traditional programming, the focus is on code. In machine learning projects, the focus shifts to representation. That is, one way developers hone a model is by adding and improving its features."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mapping Raw Data to Features\n",
        "\n",
        "The left side of Figure 1 illustrates raw data from an input data source; the right side illustrates a __feature vector__, which is the set of floating-point values comprising the examples in your data set. __Feature engineering__ means transforming raw data into a feature vector. Expect to spend significant time doing feature engineering.\n",
        "\n",
        "Many machine learning models must represent the features as real-numbered vectors since the feature values must be multiplied by the model weights."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/RawDataToFeatureVector.svg' />\n",
        "\n",
        "  <strong>Figure 1. Feature engineering maps raw data to ML features.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mapping numeric values\n",
        "\n",
        "Integer and floating-point data don't need a special encoding because they can be multiplied by a numeric weight. As suggested in Figure 2, converting the raw integer value 6 to the feature value 6.0 is trivial:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/FloatingPointFeatures.svg' />\n",
        "\n",
        "  <strong>Figure 2. Mapping integer values to floating-point values.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mapping categorical values\n",
        "\n",
        "[Categorical features](https://developers.google.com/machine-learning/glossary#categorical_data) have a discrete set of possible values. For example, there might be a feature called `street_name` with options that include:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{'Charleston Road', 'North Shoreline Boulevard', 'Shorebird Way', 'Rengstorff Avenue'}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since models cannot multiply strings by the learned weights, we use feature engineering to convert strings to numeric values.\n",
        "\n",
        "We can accomplish this by defining a mapping from the feature values, which we'll refer to as the __vocabulary__ of possible values, to integers. Since not every street in the world will appear in our dataset, we can group all other streets into a catch-all \"other\" category, known as an __OOV (out-of-vocabulary) bucket__.\n",
        "\n",
        "Using this approach, here's how we can map our street names to numbers:\n",
        "\n",
        "* map Charleston Road to 0\n",
        "* map North Shoreline Boulevard to 1\n",
        "* map Shorebird Way to 2\n",
        "* map Rengstorff Avenue to 3\n",
        "* map everything else (OOV) to 4\n",
        "\n",
        "However, if we incorporate these index numbers directly into our model, it will impose some constraints that might be problematic:\n",
        "\n",
        "* We'll be learning a single weight that applies to all streets. For example, if we learn a weight of 6 for `street_name`, then we will multiply it by 0 for Charleston Road, by 1 for North Shoreline Boulevard, 2 for Shorebird Way and so on. Consider a model that predicts house prices using `street_name` as a feature. It is unlikely that there is a linear adjustment of price based on the street name, and furthermore this would assume you have ordered the streets based on their average house price. Our model needs the flexibility of learning different weights for each street that will be added to the price estimated using the other features.\n",
        "* We aren't accounting for cases where `street_name` may take multiple values. For example, many houses are located at the corner of two streets, and there's no way to encode that information in the `street_name` value if it contains a single index.\n",
        "\n",
        "To remove both these constraints, we can instead create a binary vector for each categorical feature in our model that represents values as follows:\n",
        "\n",
        "* For values that apply to the example, set corresponding vector elements to `1`.\n",
        "* Set all other elements to `0`.\n",
        "\n",
        "The length of this vector is equal to the number of elements in the vocabulary. This representation is called a __one-hot__ encoding when a single value is 1, and a __multi-hot__ encoding when multiple values are 1.\n",
        "\n",
        "Figure 3 illustrates a one-hot encoding of a particular street: Shorebird Way. The element in the binary vector for Shorebird Way has a value of `1`, while the elements for all other streets have values of `0`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/OneHotEncoding.svg' />\n",
        "\n",
        "  <strong>Figure 3. Mapping street address via one-hot encoding.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This approach effectively creates a Boolean variable for every feature value (e.g., street name). Here, if a house is on Shorebird Way then the binary value is 1 only for Shorebird Way. Thus, the model uses only the weight for Shorebird Way.\n",
        "\n",
        "Similarly, if a house is at the corner of two streets, then two binary values are set to 1, and the model uses both their respective weights."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sparse Representation\n",
        "\n",
        "Suppose that you had 1,000,000 different street names in your data set that you wanted to include as values for `street_name`. Explicitly creating a binary vector of 1,000,000 elements where only 1 or 2 elements are true is a very inefficient representation in terms of both storage and computation time when processing these vectors. In this situation, a common approach is to use a [sparse representation](https://developers.google.com/machine-learning/glossary#sparse_representation) in which only nonzero values are stored. In sparse representations, an independent model weight is still learned for each feature value, as described above."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Qualities of Good Features\n",
        "\n",
        "We've explored ways to map raw data into suitable feature vectors, but that's only part of the work. We must now explore what kinds of values actually make good features within those feature vectors."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Avoid rarely used discrete feature values\n",
        "\n",
        "Good feature values should appear more than 5 or so times in a data set. Doing so enables a model to learn how this feature value relates to the label. That is, having many examples with the same discrete value gives the model a chance to see the feature in different settings, and in turn, determine when it's a good predictor for the label. For example, a `house_type` feature would likely contain many examples in which its value was `victorian`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_type: 'victorian'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conversely, if a feature's value appears only once or very rarely, the model can't make predictions based on that feature. For example, `unique_house_id` is a bad feature because each value would be used only once, so the model couldn't learn anything from it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_house_id: '8SK982ZZ1242Z'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prefer clear and obvious meanings\n",
        "\n",
        "Each feature should have a clear and obvious meaning to anyone on the project. For example, the following good feature is clearly named and the value makes sense with respect to the name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_age_years: 27"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conversely, the meaning of the following feature value is pretty much indecipherable to anyone but the engineer who created it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "house_age: 851472000"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In some cases, noisy data (rather than bad engineering choices) causes unclear values. For example, the following user_age_years came from a source that didn't check for appropriate values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_age_years: 277"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Don't mix \"magic\" values with actual data\n",
        "\n",
        "Good floating-point features don't contain peculiar out-of-range discontinuities or \"magic\" values. For example, suppose a feature holds a floating-point value between 0 and 1. So, values like the following are fine:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "quality_rating: 0.82\n",
        "quality_rating: 0.37"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, if a user didn't enter a `quality_rating`, perhaps the data set represented its absence with a magic value like the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "quality_rating: -1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To explicitly mark magic values, create a Boolean feature that indicates whether or not a `quality_rating` was supplied. Give this Boolean feature a name like `is_quality_rating_defined`.\n",
        "\n",
        "In the original feature, replace the magic values as follows:\n",
        "\n",
        "* For variables that take a finite set of values (discrete variables), add a new value to the set and use it to signify that the feature value is missing.\n",
        "* For continuous variables, ensure missing values do not affect the model by using the mean value of the feature's data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Account for upstream instability\n",
        "\n",
        "The definition of a feature shouldn't change over time. For example, the following value is useful because the city name _probably_ won't change. (Note that we'll still need to convert a string like \"br/sao_paulo\" to a one-hot vector.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "city_id: 'br/sao_paulo'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But gathering a value inferred by another model carries additional costs. Perhaps the value \"219\" currently represents Sao Paulo, but that representation could easily change on a future run of the other model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inferred_city_cluster: 219"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning Data\n",
        "\n",
        "Apple trees produce some mixture of great fruit and wormy messes. Yet the apples in high-end grocery stores display 100% perfect fruit. Between orchard and grocery, someone spends significant time removing the bad apples or throwing a little wax on the salvageable ones. As an ML engineer, you'll spend enormous amounts of your time tossing out bad examples and cleaning up the salvageable ones. Even a few \"bad apples\" can spoil a large data set."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scaling feature values\n",
        "\n",
        "__Scaling__ means converting floating-point feature values from their natural range (for example, 100 to 900) into a standard range (for example, 0 to 1 or -1 to +1). If a feature set consists of only a single feature, then scaling provides little to no practical benefit. If, however, a feature set consists of multiple features, then feature scaling provides the following benefits:\n",
        "\n",
        "* Helps gradient descent converge more quickly.\n",
        "* Helps avoid the \"NaN trap,\" in which one number in the model becomes a [NaN](https://wikipedia.org/wiki/NaN) (e.g., when a value exceeds the floating-point precision limit during training), and—due to math operations—every other number in the model also eventually becomes a NaN.\n",
        "* Helps the model learn appropriate weights for each feature. Without feature scaling, the model will pay too much attention to the features having a wider range.\n",
        "\n",
        "You don't have to give every floating-point feature exactly the same scale. Nothing terrible will happen if Feature A is scaled from -1 to +1 while Feature B is scaled from -3 to +3. However, your model will react poorly if Feature B is scaled from 5000 to 100000.\n",
        "\n",
        "One obvious way to scale numerical data is to linearly map [min value, max value] to a small scale, such as [-1, +1].\n",
        "\n",
        "Another popular scaling tactic is to calculate the Z score of each value. The Z score relates the number of standard deviations away from the mean. In other words:\n",
        "\n",
        "$$scaledvalue=(value−mean)/stddev.$$\n",
        "\n",
        "For example, given:\n",
        "\n",
        "* mean = 100\n",
        "* standard deviation = 20\n",
        "* original value = 130\n",
        "\n",
        "then:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaled_value = (130 - 100) / 20\n",
        "scaled_value = 1.5"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scaling with Z scores means that most scaled values will be between -3 and +3, but a few values will be a little higher or lower than that range."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling extreme outliers\n",
        "\n",
        "The following plot represents a feature called `roomsPerPerson` from the [California Housing data set](https://developers.google.com/machine-learning/crash-course/california-housing-data-description). The value of `roomsPerPerson` was calculated by dividing the total number of rooms for an area by the population for that area. The plot shows that the vast majority of areas in California have one or two rooms per person. But take a look along the x-axis."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/ScalingNoticingOutliers.svg' />\n",
        "\n",
        "  <strong>Figure 4. A verrrrry lonnnnnnng tail.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How could we minimize the influence of those extreme outliers? Well, one way would be to take the log of every value:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/ScalingLogNormalization.svg' />\n",
        "\n",
        "  <strong>Figure 5. Logarithmic scaling still leaves a tail.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Log scaling does a slightly better job, but there's still a significant tail of outlier values. Let's pick yet another approach. What if we simply \"cap\" or \"clip\" the maximum value of `roomsPerPerson` at an arbitrary value, say 4.0?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/ScalingClipping.svg' />\n",
        "\n",
        "  <strong>Figure 6. Clipping feature values at 4.0</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clipping the feature value at 4.0 doesn't mean that we ignore all values greater than 4.0. Rather, it means that all values that were greater than 4.0 now become 4.0. This explains the funny hill at 4.0. Despite that hill, the scaled feature set is now more useful than the original data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Binning\n",
        "\n",
        "The following plot shows the relative prevalence of houses at different latitudes in California. Notice the clustering — Los Angeles is about at latitude 34 and San Francisco is roughly at latitude 38."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/ScalingBinningPart1.svg' />\n",
        "\n",
        "  <strong>Figure 7. Houses per latitude.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the data set, `latitude` is a floating-point value. However, it doesn't make sense to represent `latitude` as a floating-point feature in our model. That's because no linear relationship exists between latitude and housing values. For example, houses in latitude 35 are not $\\dfrac{35}{34}$ more expensive (or less expensive) than houses at latitude 34. And yet, individual latitudes probably are a pretty good predictor of house values.\n",
        "\n",
        "To make latitude a helpful predictor, let's divide latitudes into \"bins\" as suggested by the following figure:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/ScalingBinningPart2.svg' />\n",
        "\n",
        "  <strong>Figure 8. Binning values.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of having one floating-point feature, we now have 11 distinct boolean features (`LatitudeBin1`, `LatitudeBin2`, ..., `LatitudeBin11`). Having 11 separate features is somewhat inelegant, so let's unite them into a single 11-element vector. Doing so will enable us to represent latitude 37.4 as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thanks to binning, our model can now learn completely different weights for each latitude.\n",
        "\n",
        "For simplicity's sake in the latitude example, we used whole numbers as bin boundaries. Had we wanted finer-grain resolution, we could have split bin boundaries at, say, every tenth of a degree. Adding more bins enables the model to learn different behaviors from latitude 37.4 than latitude 37.5, but only if there are sufficient examples at each tenth of a latitude.\n",
        "\n",
        "Another approach is to bin by [quantile](https://wikipedia.org/wiki/Quantile), which ensures that the number of examples in each bucket is equal. Binning by quantile completely removes the need to worry about outliers."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scrubbing\n",
        "\n",
        "Until now, we've assumed that all the data used for training and testing was trustworthy. In real-life, many examples in data sets are unreliable due to one or more of the following:\n",
        "\n",
        "* __Omitted values.__ For instance, a person forgot to enter a value for a house's age.\n",
        "* __Duplicate examples.__ For example, a server mistakenly uploaded the same logs twice.\n",
        "* __Bad labels.__ For instance, a person mislabeled a picture of an oak tree as a maple.\n",
        "* __Bad feature values.__ For example, someone typed in an extra digit, or a thermometer was left out in the sun.\n",
        "\n",
        "Once detected, you typically \"fix\" bad examples by removing them from the data set. To detect omitted values or duplicated examples, you can write a simple program. Detecting bad feature values or labels can be far trickier.\n",
        "\n",
        "In addition to detecting bad individual examples, you must also detect bad data in the aggregate. Histograms are a great mechanism for visualizing your data in the aggregate. In addition, getting statistics like the following can help:\n",
        "\n",
        "* Maximum and minimum\n",
        "* Mean and median\n",
        "* Standard deviation\n",
        "\n",
        "Consider generating lists of the most common values for discrete features. For example, do the number of examples with `country:uk` match the number you expect. Should `language:jp` really be the most common language in your data set?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Know your data\n",
        "\n",
        "Follow these rules:\n",
        "\n",
        "* Keep in mind what you think your data should look like.\n",
        "* Verify that the data meets these expectations (or that you can explain why it doesn’t).\n",
        "* Double-check that the training data agrees with other sources (for example, dashboards).\n",
        "\n",
        "Treat your data with all the care that you would treat any mission-critical code. Good ML relies on good data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Crosses\n",
        "\n",
        "A __feature cross__ is a __synthetic feature__ formed by multiplying (crossing) two or more features. Crossing combinations of features can provide predictive abilities beyond what those features can provide individually."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encoding Nonlinearity\n",
        "\n",
        "In Figures 1 and 2, imagine the following:\n",
        "\n",
        "* The blue dots represent sick trees.\n",
        "* The orange dots represent healthy trees."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/machine-learning/crash-course/images/LinearProblem1.png' />\n",
        "\n",
        "  <strong>Figure 1. Is this a linear problem?</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can you draw a line that neatly separates the sick trees from the healthy trees? Sure. This is a linear problem. The line won't be perfect. A sick tree or two might be on the \"healthy\" side, but your line will be a good predictor.\n",
        "\n",
        "Now look at the following figure:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/machine-learning/crash-course/images/LinearProblem2.png' />\n",
        "\n",
        "  <strong>Figure 2. Is this a linear problem?</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can you draw a single straight line that neatly separates the sick trees from the healthy trees? No, you can't. This is a nonlinear problem. Any line you draw will be a poor predictor of tree health."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/machine-learning/crash-course/images/LinearProblemNot.png' />\n",
        "\n",
        "  <strong>Figure 3. A single line can't separate the two classes.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To solve the nonlinear problem shown in Figure 2, create a feature cross. A __feature cross__ is a synthetic feature that encodes nonlinearity in the feature space by multiplying two or more input features together. (The term cross comes from [cross product](https://wikipedia.org/wiki/Cross_product).) Let's create a feature cross named $x_{3}$ by crossing $x_{1}$ and $x_{2}$:\n",
        "\n",
        "$$x_{3}=x_{1}x_{2}$$\n",
        "\n",
        "We treat this newly minted $x_{3}$ feature cross just like any other feature. The linear formula becomes:\n",
        "\n",
        "$$y=b+w_{1}x_{1}+w_{2}x_{2}+w_{3}x_{3}$$\n",
        "\n",
        "A linear algorithm can learn a weight for $w_{3}$ just as it would for $w_{1}$ and $w_{2}$. In other words, although $w_{3}$ encodes nonlinear information, you don’t need to change how the linear model trains to determine the value of $w_{3}$."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kinds of feature crosses\n",
        "\n",
        "We can create many different kinds of feature crosses. For example:\n",
        "\n",
        "* `[A X B]`: a feature cross formed by multiplying the values of two features.\n",
        "* `[A x B x C x D x E]`: a feature cross formed by multiplying the values of five features.\n",
        "* `[A x A]`: a feature cross formed by squaring a single feature.\n",
        "\n",
        "Thanks to [stochastic gradient descent](https://developers.google.com/machine-learning/crash-course/reducing-loss/stochastic-gradient-descent), linear models can be trained efficiently. Consequently, supplementing scaled linear models with feature crosses has traditionally been an efficient way to train on massive-scale data sets."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Crossing One-Hot Vectors\n",
        "\n",
        "So far, we've focused on feature-crossing two individual floating-point features. In practice, machine learning models seldom cross continuous features. However, machine learning models do frequently cross one-hot feature vectors. Think of feature crosses of one-hot feature vectors as logical conjunctions. For example, suppose we have two features: country and language. A one-hot encoding of each generates vectors with binary features that can be interpreted as `country=USA`, `country=France` or `language=English`, `language=Spanish`. Then, if you do a feature cross of these one-hot encodings, you get binary features that can be interpreted as logical conjunctions, such as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "country: 'usa' AND language: 'spanish'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As another example, suppose you bin latitude and longitude, producing separate one-hot five-element feature vectors. For instance, a given latitude and longitude could be represented as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "binned_latitude = [0, 0, 0, 1, 0]\n",
        "binned_longitude = [0, 1, 0, 0, 0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose you create a feature cross of these two feature vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "binned_latitude X binned_longitude"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This feature cross is a 25-element one-hot vector (24 zeroes and 1 one). The single `1` in the cross identifies a particular conjunction of latitude and longitude. Your model can then learn particular associations about that conjunction.\n",
        "\n",
        "Suppose we bin latitude and longitude much more coarsely, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "binned_latitude(lat) = [\n",
        "  0  < lat <= 10\n",
        "  10 < lat <= 20\n",
        "  20 < lat <= 30\n",
        "]\n",
        "\n",
        "binned_longitude(lon) = [\n",
        "  0  < lon <= 15\n",
        "  15 < lon <= 30\n",
        "]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a feature cross of those coarse bins leads to synthetic feature having the following meanings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "binned_latitude_X_longitude(lat, lon) = [\n",
        "  0  < lat <= 10 AND 0  < lon <= 15\n",
        "  0  < lat <= 10 AND 15 < lon <= 30\n",
        "  10 < lat <= 20 AND 0  < lon <= 15\n",
        "  10 < lat <= 20 AND 15 < lon <= 30\n",
        "  20 < lat <= 30 AND 0  < lon <= 15\n",
        "  20 < lat <= 30 AND 15 < lon <= 30\n",
        "]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now suppose our model needs to predict how satisfied dog owners will be with dogs based on two features:\n",
        "\n",
        "* Behavior type (barking, crying, snuggling, etc.)\n",
        "* Time of day\n",
        "\n",
        "If we build a feature cross from both these features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[behavior_type X time_of_day]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "then we'll end up with vastly more predictive ability than either feature on its own. For example, if a dog cries (happily) at 5:00 pm when the owner returns from work will likely be a great positive predictor of owner satisfaction. Crying (miserably, perhaps) at 3:00 am when the owner was sleeping soundly will likely be a strong negative predictor of owner satisfaction.\n",
        "\n",
        "Linear learners scale well to massive data. Using feature crosses on massive data sets is one efficient strategy for learning highly complex models. [Neural networks](https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks) provide another strategy."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Regularization for Simplicity\n",
        "\n",
        "__Regularization__ means penalizing the complexity of a model to reduce overfitting."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## L2 Regularization\n",
        "\n",
        "Consider the following __generalization curve__, which shows the loss for both the training set and validation set against the number of training iterations."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/RegularizationTwoLossFunctions.svg' />\n",
        "\n",
        "  <strong>Figure 1. Loss on training set and validation set.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Figure 1 shows a model in which training loss gradually decreases, but validation loss eventually goes up. In other words, this generalization curve shows that the model is [overfitting](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting) to the data in the training set. Channeling our inner [Ockham](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting#ockham), perhaps we could prevent overfitting by penalizing complex models, a principle called __regularization__.\n",
        "\n",
        "In other words, instead of simply aiming to minimize loss (empirical risk minimization):\n",
        "\n",
        "$$\\mathrm{minimize(Loss(Data \\vert Model))}$$\n",
        "\n",
        "we'll now minimize loss+complexity, which is called __structural risk minimization__.\n",
        "\n",
        "$$\\mathrm{minimize(Loss(Data \\vert Model) + \\mathrm{complexity(Model)})}$$\n",
        "\n",
        "Our training optimization algorithm is now a function of two terms: the __loss term__, which measures how well the model fits the data, and the __regularization term__, which measures model complexity.\n",
        "\n",
        "There are two commom ways to think of model complexity:\n",
        "\n",
        "  * Model complexity as a function of the _weights_ of all the features in the model.\n",
        "  * Model complexity as a function of the _total number of features_ with nonzero weights.\n",
        "\n",
        "If model complexity is a function of weights, a feature weight with a high absolute value is more complex that a feature weight with a low absolute value.\n",
        "\n",
        "We can quantify complexity using the $L_{2}$ __regularization__ formula, which defines the regularization term as the sum of the squares of all the feature weights:\n",
        "\n",
        "$$\\mathrm{L_{2}\\ regularization\\ term} = \\mathrm{\\lvert \\lvert w \\rvert \\rvert}^2_{2} = w_{1}^2 + w_{2}^2 + ... + w_{n}^2$$\n",
        "\n",
        "In this formula, weights close to zero have little effect on model complexity, while outlier weights can have a huge impact.\n",
        "\n",
        "For example, a linear model with the following weights:\n",
        "\n",
        "$$\\{w_{1} = 0.2, w_{2} = 0.5, w_{3} = 5, w_{4} = 1, w_{5} = 0.25, w_{6} = 0.75\\}$$\n",
        "\n",
        "Has an $L_{2}$ regularization term of 26.915:\n",
        "\n",
        "$$\n",
        "w_{1}^2 + w_{2}^2 + w_{3}^2 + w_{4}^2 + w_{5}^2 + w_{6}^2 \\\\\n",
        "= 0.2^2 + 0.5^2 + 5^2 + 1^2 + 0.25^2 + 0.75^2 \\\\\n",
        "= 0.04 + 0.24 + 25 + 1 + 0.0625 + 0.5625 \\\\\n",
        "= 26.915\n",
        "$$\n",
        "\n",
        "But $w_{3}$, with a squared value of 25, contributes nearly all the complexity. The sum of the squares of all five other weights adds just 1.915 to the $L_{2}$ regularization term."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lambda\n",
        "\n",
        "Model developers tune the overall impact of the regularization term by multiplying its value by a scalar known as __lambda__ (also called the __regularization rate__). That is, model devvelopers aim to do the following:\n",
        "\n",
        "$$\\mathrm{minimize(Loss(Data \\vert Model) + \\lambda \\ complexity(Model))}$$\n",
        "\n",
        "Performing $L_{2}$ regularization has the following effect on the model:\n",
        "\n",
        "  * Encourages weight values toward 0 (but not exactly 0).\n",
        "  * Encourages the mean of the weights toward 0, with a normal (bell-shaped or Gaussian) distribution.\n",
        "\n",
        "Increasing the lambda value strengthens the regularization effect. For example, the histogram of weights for a high value of lambda might look as shown in Figure 2."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/HighLambda.svg' />\n",
        "\n",
        "  <strong>Figure 2. Histogram of weights.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lowering the value of lambda tends to yield a flatter histogram, as shown in Figure 3."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/LowLambda.svg' />\n",
        "\n",
        "  <strong>Figure 3. Histogram of weights produced by a lower lambda value.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When choosing a lambda value, the goal is to strike the right balance between simplicity and training-data fit:\n",
        "\n",
        "* If your lambda value is too high, your model will be simple, but you run the risk of underfitting your data. Your model won't learn enough about the training data to make useful predictions.\n",
        "* If your lambda value is too low, your model will be more complex, and you run the risk of overfitting your data. Your model will learn too much about the particularities of the training data, and won't be able to generalize to new data.\n",
        "\n",
        "The ideal value of lambda produces a model that generalizes well to new, previously unseen data. Unfortunately, that ideal value of lambda is data-dependent, so you'll need to do some tuning."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### L2 regularization and Learning rate\n",
        "\n",
        "There's a close connection between learning rate and lambda. Strong L2 regularization values tend to drive feature weights closer to 0. Lower learning rates (with early stopping) often produce the same effect because the steps away from 0 aren't as large. Consequently, tweaking learning rate and lambda simultaneously may have confounding effects.\n",
        "\n",
        "__Early stopping__ means ending training before the model fully reaches convergence. In practice, we often end up with some amount of implicit early stopping when training in an [online](https://developers.google.com/machine-learning/crash-course/production-ml-systems) (continuous) fashion. That is, some new trends just haven't had enough data yet to converge.\n",
        "\n",
        "As noted, the effects from changes to regularization parameters can be confounded with the effects from changes in learning rate or number of iterations. One useful practice (when training across a fixed batch of data) is to give yourself a high enough number of iterations that early stopping doesn't play into things."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logistic Regression\n",
        "\n",
        "Instead of predicting _exactly_ 0 or 1, __logistic regression__ generates a probability—a value between 0 and 1, exclusive. For example, consider a logistic regression model for spam detection. If the model infers a value of 0.932 on a particular email message, it implies a 93.2% probability that the email message is spam. More precisely, it means that in the limit of _infinite_ training examples, the set of examples for which the model predicts 0.932 will actually be spam 93.2% of the time and the remaining 6.8% will not."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculating a Probability\n",
        "\n",
        "Many problems require a probability estimate as output. Logistic regression is an extremely efficient mechanism for calculating probabilities. Practically speaking, you can use the returned probability in either of the following two ways:\n",
        "\n",
        "* \"As is\"\n",
        "* Converted to a binary category.\n",
        "\n",
        "Let's consider how we might use the probability \"as is.\" Suppose we create a logistic regression model to predict the probability that a dog will bark during the middle of the night. We'll call that probability:\n",
        "\n",
        "$$\\mathrm{p}(\\mathrm{bark} \\vert \\mathrm{night})$$\n",
        "\n",
        "If the logistic regression model predicts $\\mathrm{p}(\\mathrm{bark} \\vert \\mathrm{night}) = 0.05$, then over a year, the dog's owners should be startled awake approximately 18 times:\n",
        "\n",
        "$$\\mathrm{startled} = \\mathrm{p}(\\mathrm{bark} \\vert \\mathrm{night}) \\cdot \\mathrm{nights}$$\n",
        "$$= 0.05 \\cdot 365$$\n",
        "$$= 18$$\n",
        "\n",
        "In many cases, you'll map the logistic regression output into the solution to a binary classification problem, in which the goal is to correctly predict one of two possible labels (e.g., \"spam\" or \"not spam\").\n",
        "\n",
        "You might be wondering how a logistic regression model can ensure output that always falls between 0 and 1. As it happens, a __sigmoid function__, defined as follows, produces output having those same characteristics:\n",
        "\n",
        "$$y = \\dfrac{1}{1 + e^{-z}}$$\n",
        "\n",
        "The sigmoid function yields the following plot:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/machine-learning/crash-course/images/SigmoidFunction.png' />\n",
        "\n",
        "  <strong>Figure 1: Sigmoid function.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If $z$ represents the output of the linear layer of a model trained with logistic regression, then $sigmoid(z)$ will yield a value (a probability) between 0 and 1. In mathematical terms:\n",
        "\n",
        "$$y^ \\prime = \\dfrac{1}{1 + e^{-z}}$$\n",
        "\n",
        "where:\n",
        "\n",
        "* $y^ \\prime$ is the output of the logistic regression model for a particular example.\n",
        "* $z = b + w_{1}x_{1} + w_{2}x_{2} + ... + w_{N}x_{N}$\n",
        "  * The $w$ values are the model's learned weights, and $b$ is the bias.\n",
        "  * The $x$ values are the feature values for a particular example.\n",
        "\n",
        "Note that $z$ is also referred to as the _log-odds_ because the inverse of the sigmoid states that $z$ can be defined as the log of the probability of the 1 label (eg., \"dog barks\") divided by the probability of the 0 label (eg., \"dog doesn't bark\"):\n",
        "\n",
        "$$z = \\mathrm{log} \\left( \\dfrac{y}{1- y} \\right)$$\n",
        "\n",
        "Here is the sigmoid function with ML labels:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align='center'>\n",
        "  <img src='https://developers.google.com/static/machine-learning/crash-course/images/LogisticRegressionOutput.svg' />\n",
        "\n",
        "  <strong>Figure 2: Logistic regression output.</strong>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loss and Regularization"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss function for Logistic Regression\n",
        "\n",
        "The loss function for linear regression is squared loss. The loss function for logistic regression is __Log Loss__, which is defined as follows:\n",
        "\n",
        "$$\\mathrm{Log\\ Loss} = \\sum_{(x,y) \\in D} -ylog(y^ \\prime) - (1 - y)log(1 - y^ \\prime)$$\n",
        "\n",
        "where:\n",
        "\n",
        "* $(x,y) \\in D$ is the data set containing many labeled examples, which are $(x,y)$ pairs.\n",
        "* $y$ is the label in a labeled example. Since this is logistic regression, every value of $y$ must either be 0 or 1.\n",
        "* $y^ \\prime$ is the predicted value (somewhere between 0 and 1), given the set of features in $x$."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regularization in Logistic Regression\n",
        "\n",
        "[Regularization](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/video-lecture) is extremely important in logistic regression modeling. Without regularization, the asymptotic nature of logistic regression would keep driving loss towards 0 in high dimensions. Consequently, most logistic regression models use one of the following two strategies to dampen model complexity:\n",
        "\n",
        "* $L_{2}$ regularization\n",
        "* Early stopping, that is, limiting the number of training steps or the learning rate.\n",
        "\n",
        "Imagine that you assign a unique id to each example, and map each id to its own feature. If you don't specify a regularization function, the model will become completely overfit. That's because the model would try to drive loss to zero on all examples and never get there, driving the weights for each indicator feature to +infinity or -infinity. This can happen in high dimensional data with feature crosses, when there’s a huge mass of rare crosses that happen only on one example each.\n",
        "\n",
        "Fortunately, using L2 or early stopping will prevent this problem."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Thresholding\n",
        "\n",
        "Logistic regression returns a probability. You can use the returned probability \"as is\" (for example, the probability that the user will click on this ad is 0.00023) or convert the returned probability to a binary value (for example, this email is spam).\n",
        "\n",
        "A logistic regression model that returns 0.9995 for a particular email message is predicting that it is very likely to be spam. Conversely, another email message with a prediction score of 0.0003 on that same logistic regression model is very likely not spam. However, what about an email message with a prediction score of 0.6? In order to map a logistic regression value to a binary category, you must define a __classification threshold__ (also called the __decision threshold__). A value above that threshold indicates \"spam\"; a value below indicates \"not spam.\" It is tempting to assume that the classification threshold should always be 0.5, but thresholds are problem-dependent, and are therefore values that you must tune."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## True vs. False and Positive vs. Negative\n",
        "\n",
        "In this section, we'll define the primary building blocks of the metrics we'll use to evaluate classification models. But first, a fable:\n",
        "\n",
        "> __An Aesop's Fable: The Boy Who Cried Wolf (compressed)__\n",
        ">\n",
        "> A shepherd boy gets bored tending the town's flock. To have some fun, he cries out, \"Wolf!\" even though no wolf is in sight. The villagers run to protect the flock, but then get really mad when they realize the boy was playing a joke on them.\n",
        ">\n",
        "> [Iterate previous paragraph N times.]\n",
        ">\n",
        "> One night, the shepherd boy sees a real wolf approaching the flock and calls out, \"Wolf!\" The villagers refuse to be fooled again and stay in their houses. The hungry wolf turns the flock into lamb chops. The town goes hungry. Panic ensues.\n",
        "\n",
        "Let's make the following definitions:\n",
        "\n",
        "* \"Wolf\" is a __positive class__.\n",
        "* \"No wolf\" is a __negative class__.\n",
        "\n",
        "We can summarize our \"wolf-prediction\" model using a 2x2 [confusion matrix](https://developers.google.com/machine-learning/glossary#confusion_matrix) that depicts all four possible outcomes:\n",
        "\n",
        "* __True Positive (TP):__\n",
        "  * Reality: A wolf threatened.\n",
        "  * Shepherd said: \"Wolf.\"\n",
        "  * Outcome: Shepherd is a hero.\n",
        "\n",
        "* __False Positive (FP):__\n",
        "  * Reality: No wolf threatened.\n",
        "  * Shepherd said: \"Wolf.\"\n",
        "  * Outcome: Villagers are angry at shepherd for waking them up.\n",
        "\n",
        "* __True Negative (TN):__\n",
        "  * Reality: No wolf threatened.\n",
        "  * Shepherd said: \"No wolf.\"\n",
        "  * Outcome: Everyone is fine.\n",
        "\n",
        "* __False Negative (FN):__\n",
        "  * Reality: A wolf threatened.\n",
        "  * Shepherd said: \"No wolf.\"\n",
        "  * Outcome: The wolf ate all the sheep.\n",
        "\n",
        "A __true positive__ is an outcome where the model correctly predicts the positive class. Similarly, a __true negative__ is an outcome where the model correctly predicts the negative class.\n",
        "\n",
        "A __false positive__ is an outcome where the model incorrectly predicts the positive class. And a __false negative__ is an outcome where the model incorrectly predicts the negative class."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "d6f2081d9e0b7d32ecec298930d2c84146e44d12c2a59792b9d51f0a2535e83c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
